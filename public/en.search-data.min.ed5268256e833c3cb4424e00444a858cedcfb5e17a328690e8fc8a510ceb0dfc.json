[{"id":0,"href":"/announcements/week-0/","title":"Week 0","section":"Announcements","content":" The Linux SysAdmin Decal is back for Spring 2025! Join us at Decal infosessions on 1/28 and 1/30, 7pm @ OCF Lab or at ocf.io/meet! If you weren\u0026rsquo;t able to make it to an infosession, access the slides here. To enroll, fill out lab 0 here! Lab 0 is due Saturday, Feb. 1st at 11:59pm and enrollment keys will be sent to those who complete it. Learn more about the course at the about page. Any questions? Contact us at decal@ocf.berkeley.edu! Looking for a previous semester\u0026rsquo;s materials? You can view it in the archive. "},{"id":1,"href":"/about/","title":"About","section":"Home","content":" About # Course Description # This course covers the basics of setting up and administering a production-quality Linux server environment. By the end of this course, we expect that you will\u0026hellip;\nbe comfortable using GNU/Linux understand how different parts of the OS work together, e.g. init, processes, daemons, filesystems, etc. understand basic networking on Linux have a good sense about maintaining system security understand system administration essentials get a practical taste of what sysadmins do in industry. While we expect many students will have a CS background, the only real prerequisite is a desire to learn about new and unfamiliar technologies, which is a critical skill for sysadmins. This course is designed to introduce new users to Linux, as well as give more experienced users a taste of what Linux is capable of!\nAdministrivia # Enrollment # This is a 2 unit DeCal. Since it is a DeCal, the course is P/NP. You must complete Lab 0 to apply. If you are selected for the course, we will send you a course enrollment code.\nCommunication # Official course communications will primarily be sent via email (through Ed announcements), and mirrored on the front page of the course website.\nThere are several ways you can get in contact with course facilitators:\nMake a post on Ed. (best for conceptual/debugging/content help) Send a message to #decal-general (or as a private message to a facilitator) either on Slack or Discord. (best for realtime communications) Email decal@ocf.berkeley.edu. (best for prospective students and matters that need to go on official record) Lecture # Lectures for this course are synchronous (see the weekly schedule on the home page for the time and location). We will do our best to provide recordings at the beginning of each week as well. There will be 10 total required lectures for each track, as well as one optional guest lecture.\nA short participation assignment (vitamin) will be released every week with some questions to check your understanding on lecture and reading. We require 5 out of 10 of the vitamins to be completed, and if you compete all 10, we will grant you 1 lab drop.\nLab Assignments # The primary assignment in this course will be weekly lab work. Labs are designed to be be significantly hands-on. You will be working on real systems, configuring and fixing things, setting up services, and so on.\nEach lecture corresponds with a lab and will be releasedon Sundays.\nEach lab will be due by the Saturday, 11:59pm PST after the lab section unless otherwise stated.\nYou must complete 10 labs to receive credit for taking the course. The late due date for labs is 2 weeks after the original due date. You may submit up to 2 labs late throughout the semester without penalty.\nIf you need to request an excused lab extension or drop, please fill out this form. Doing so will not affect your two unexcused late labs.\nYou are highly encouraged to look over the lab, and try to start it, before coming to live lab sections each week. This will allow you to better utilize the help of the facilitators.\nLive Labs # During lab sections, facilitators will be able to give additional information, and hold office hours to answer any questions that may arise. Lab sections will be held in the OCF lab (171 MLK, click here for directions).\nGrading # The following are required to receive credit for the course:\n10 completed lab assignments Lab assignments are graded on completion, not correctness. Blank or otherwise extremely low-effort submissions (i.e. no visible attempt at answering the questions asked) will be considered incomplete. At least 5 completed participation assignments (vitamins) If you complete all 10 of the vitamins, we will grant you 1 lab drop. FAQ # Will the DeCal be offered next semester? # Most likely. We are aiming to offer the decal every semester! You can check announcements or reach out to the decal committee over discord/slack.\nI don\u0026rsquo;t want units / wasn\u0026rsquo;t accepted / am not a student. Can I audit this course? # We are working hard to get all of our materials online this semester for everyone to access! Feel free to view our lectures or complete any of the labs on your own. (You will need your own Linux VM though- you can install one locally or get one from a provider such as DigitalOcean.)\nI\u0026rsquo;m stuck on a lab/concept! Where can I find help? # The best way to get support with course content is to ask during scheduled lab times. If you need help at another time, feel free to ask on Ed, on our Slack channel at #decal-general, or on our Discord channel. Logistics questions are best suited for email ( decal@ocf.berkeley.edu).\nI have another question! # Email us at decal@ocf.berkeley.edu.\nAfter this Course # There\u0026rsquo;s no substitute for real-world experience. If you\u0026rsquo;d like to get experience in a low-risk but real-world setting, consider joining the OCF as a volunteer staff member. There, you\u0026rsquo;ll be able to put the things you learn in this course to use, and help other students while you\u0026rsquo;re at it. Best of all- there\u0026rsquo;s no application process! Just drop by and say hi :)\nWeekly staff meetings are held Wednesdays at 8pm at the OCF lab.\n"},{"id":2,"href":"/labs/1/","title":"Lab 1 - Unix, the Shell, OSS","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Introduction # Welcome to the first lab!\nAll labs are graded on completeness and effort, so don\u0026rsquo;t worry too much about getting an exact right answer. (We\u0026rsquo;ll release staff solutions after the lab is due!)\nLabs are also usually due a week from when they are assigned. Remember to ask for help if you need it on Edstem or Discord/Slack!\nIt may be convenient to submit your answers to Gradescope as you go.\nPro Tips:\nHere are some commands you might find helpful: vim, ls, cd, man, file, grep, cat, less, wget, nano, tar, ..., (and other inferior text editors) Google and man are your friends! Part 1: Shell spelunking # Everything should be done via the shell!\nThe purpose of this lab is to get you comfortable with using the shell for things you might typically use a GUI for. While these tasks may seem simplistic or limited, you\u0026rsquo;ll quickly find that the commands have many different options (flags) to perform tasks that are either impossible or incredibly tedious / difficult to complete using traditional methods.\nDon\u0026rsquo;t worry about fully understanding how the commands work just yet- as long as you can gain a sense of familiarity with the tools at hand, we\u0026rsquo;ll be in good shape to explore them further next week!\nssh into tsunami.ocf.berkeley.edu using your OCF account, or login at ssh.ocf.berkeley.edu\nRun the following command to download the file we have provided: wget https://github.com/0xcf/decal-labs/raw/master/b1/b01.tgz\nA .tgz file is actually a composition of two file formats. Sometimes you\u0026rsquo;ll see these files as .tar.gz instead. A common (and old) way of archiving is with magnetic tapes. However, in order to archive the data, it needs to be a single file, and often you want to archive multiple files at once. This is where the tar command comes in (tar stands for tape archive). Tar will group (or ungroup) multiple files into a single one.\ntar, unless you ask it to, doesn\u0026rsquo;t compress files itself though. This is where either gzip (or bzip2) comes in. gzip will compress your file, and so, tar + gzip is often used in conjunction. It looks something like this: file --(tar)--\u0026gt; file.tar --(gzip)--\u0026gt; file.tar.gz.\nIf you read the tar documentation carefully enough, you\u0026rsquo;ll see that you can give the command an option to compress your files using gzip as well, saving you a total of one line of shell command!\nTo unarchive the file we provide you, run the following command: tar xvzf b01.tgz. This will provide a b01 directory for you with some files for the rest of this lab.\ntar has a reputation for being a bit tricky with its options: Go into the b01 directory. Make sure you\u0026rsquo;re in there by running pwd (Present working directory). What does pwd give you (conceptually)?\nThere\u0026rsquo;s a hidden file in the b01 directory. What is the secret?\nA malicious user made its way into my computer and created a message split across all the files in nonsense/. What does it say? How did you find the message?\nGo ahead and delete everything in nonsense/ with one command. How did you do it?\nThere\u0026rsquo;s a file in b01 called big_data.txt. It\u0026rsquo;s 80 megabytes worth of random text. For reference, Leo Tolstoy\u0026rsquo;s \u0026ldquo;War and Peace\u0026rdquo;, the novel with a whopping 57,287 words depicting the French invasion of Russia and the impact of the Napoleonic era on Tsarist society through the stories of five Russian aristocratic families with several chapters solely dedicated to philosophical prose, is only 3.2 megabytes large.\nFor that reason, I don\u0026rsquo;t recommend using cat to print the file. You can try it, but you\u0026rsquo;ll be sitting there for a while. There\u0026rsquo;s some text you need to find in there! Go find it without actually opening up the file itself!\nTwo lines above the only URL in the file is a secret solution. What is that solution?\nHints: What makes up a URL (https\u0026hellip;)? What is Context Line Control?\nTry executing ./a_script. You should get something back that says permission denied: ./a_script. This is because files have three different permissions: read, write, and execute. Which one does a_script need? Change the file permissions so that you can run the script. How did you do it?\nFinally, there\u0026rsquo;s an empty file called hello_world in the directory. Write your name in it! How did you do it?\nPart 2: General Questions # Feel free to use Google and work in a terminal (where applicable) to verify your conjectures.\nWhat differentiates Linux/OSX from operating systems like Windows?\nWhat are some differences between the command line and normal (graphical) usage of an OS?\nWhat is the root directory in Linux filesystems? Answer conceptually, as in depth as you would like,\nls has a lot of cool arguments. Try using them to get extra information such as file permissions, owner name, owner group, file size, and late date edited. In addition, I want to be able to see the size and have the files ordered by last date edited, with the oldest files on top. How would I do this?\nInstead of showing the first 10 lines of the file big_data.txt, I want to use the head command to show the first 4. How would I do that?\nWhat\u0026rsquo;s the difference between cat foo \u0026gt; out.txt and cat foo \u0026gt;\u0026gt; out.txt?\nBriefly, what is the difference between permissive and copyleft licenses?\nGive an example of a permissive license.\nGive an example of (a) open-source software and (b) free, but closed-source software that you use.\nPart 3: Obtaining your VM # Using the public OCF login server will allow you to do basic things like the lab above, but if you want root permission (which lets you do basically whatever you want), you\u0026rsquo;ll need your own use/destroy!\nWe will be providing a virtual machine (VM) to all DeCal students with a Berkeley CalNet account. Check your @berkeley.edu email!\nIf you are not a Berkeley student, then you will have to obtain your own machine. Of course, you can also set up your own VM if you are just curious. Generally, there are two ways to obtain a VM: use your own computer (local) or use someone else\u0026rsquo;s computer (cloud).\nLocal Setups: # Virtual Box UTM - Only for MacOS Cloud Setups: # These are usually paid services, but if you have a student email, they provide more than enough free credits for the purposes of this course.\nDigital Ocean GCP Azure "},{"id":3,"href":"/announcements/week-1/","title":"Week 1","section":"Announcements","content":"Hi all, this is our first official week for this semester\u0026rsquo;s Linux SysAdmin decal! Enrollment codes will be emailed by Monday to students that was accepted. Our lecture and lab will be at their normal time on Tuesday 7-8pm and 8-9pm respectively. If you\u0026rsquo;re in the Experimental Decal, it will be on Thursday 7-8pm and 8-9pm. The lab is now open and you can get a head start if you wish, or you can start during lab time. We\u0026rsquo;re looking forward to teaching this class and hope you find the content engaging!\nHere are some notes for the week:\nNormal schedule begins this week (see calendar below). Enrollment codes will be sent out by Monday. First lecture will be the day after that! You should soon also have access to Ed and Gradescope. Please use Ed for class discussion! Lab 1 is open and is due 02/08 at 11:59PM PST. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":4,"href":"/labs/2/","title":"Lab 2 - Core Shell \u0026 Shell Scripting","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Welcome to Lab 2! In this lab you will be learning how to work productively in a shell and use that to write your first shell script.\nRemember to submit your answers in the Gradescope assignment!\nDon\u0026rsquo;t forget to use Google and man when stuck. The resources linked at the bottom may be helpful as well.\nSetting up # This lab can be completed either on tsunami by logging in using ssh or on the VM you set up in the previous lab. This lab requires a bash shell, vim, and tmux. If you do not have tmux or vim installed: sudo apt install vim tmux\nA quick intro to vim # vim is a very widely used text editor. It\u0026rsquo;s well known for its customizability and plethora of keybinds. While it may be somewhat unintuitive to use at first (since a lot of common keybinds for things like copy-paste, saving, or exiting don\u0026rsquo;t do what you think they will), it\u0026rsquo;s well worth learning about, and you\u0026rsquo;ll certainly come across it all the time when working in the shell!\nWhy vim? # It\u0026rsquo;s a descendant of vi, which was written in Berkeley by Bill Joy, who went on to found Sun Microsystems. Sometimes you will be suddenly thrown into vim via merging git conflicts or other programs. It\u0026rsquo;s included in practically every UNIX environment. You can be very productive when familiar with it. Hello World # To get started with learning vim, run the command vimtutor. This will walk you through the below material in an interactive manner! You aren\u0026rsquo;t required to finish the entire tutorial, but we encourage you to at least complete lesson 1. You can then use this section as reference if you forget anything.\nThe vim Modes # Vim is a modal text editor, meaning that you can change editing modes in order to do different things. There are 3 primarily used modes: Normal, Insert, and Visual mode.\nNormal mode: # Used for moving around and performing actions hjkl to move left, up, down, and right (arrow keys work too but hjkl is usually faster to use!) G to move to end of file, gg to move to beginning i to enter insert mode (a, o also change mode in different ways) dd to cut a line yy to copy a line p to paste / to search u to undo Type in commands with : Save with :w Exit with :q Explore more commands online! Here\u0026rsquo;s a cool cheat sheet to get you started. Insert mode: # Used for editing text like a usual editor Arrow keys to move Esc to exit to normal mode (lots of people bind it to Caps Lock) Visual mode: # Enter with v from normal mode Used to select text visually Modify selection with normal mode movement commands Use o to move the cursor to the other side of the selection Yanking, deleting, and pasting use y, d, p (sound familiar?) A key feature of vim is chaining together commands. Normal mode is essentially a massive amount of shortcuts that you can combine to quickly navigate and edit a file. Want to move down 3 lines? You know that j means move down 1 line, so you can use 3j to move down 3. d is for deletion and w is to jump to the next word, so what does dw do?\nQuestions # Try playing around with lab2.md while looking up some new commands. Use wget to download it!\nHow would you delete the previous 10 lines? How would you jump back to the shell without exiting vim? How would you edit a new file alongside another file? How would you indent a block of text? Tell us about one other cool vim feature you found out about that isn\u0026rsquo;t mentioned in this lab! A quick intro to tmux(Optional) # While we reccomend that you complete this section of the lab, it\u0026rsquo;s completely optional and will not affect your lab grade. Feel free to skip ahead to the Scripting Section.\nWhy tmux? # You can open multiple windows when sshed into a machine. You can go compile and run programs while editing them. You can logout and ssh back in without having to reopen all your files. Getting Started: # Start a session with tmux. Detach from a session with Ctrl-b d (press d after releasing Ctrl-b) Split into 2 panes with Ctrl-b % (vertical) or Ctrl-b \u0026quot; (horizontal) Swap current pane with Ctrl-b o Find more information about tmux online. You might find [this cheat sheet][Tmux cheat sheet] helpful! Questions (Optional) # Make a new tmux session. Using tmux shortcuts, try to make your session have a similar layout to the one below, and upload a screenshot of it to Gradescope! Some things to note:\nThe top left panel is resized. By how much, it doesn\u0026rsquo;t matter. The top right panel is named \u0026ldquo;Hello World\u0026rdquo;. (You can see this name displayed on the bottom left.) You don\u0026rsquo;t need to run any of the commands I did, but they do look pretty cool :) Try to figure out what command the bottom panel is running, and what it does! Don\u0026rsquo;t worry about copying the layout exactly. The purpose of this exercise is simply to help you get comfortable making custom layouts in tmux. If you haven\u0026rsquo;t already, detach from your current tmux session using Ctrl+b d. Now, what command would you type to attach back to it? What command will delete your session? What command will create a new session? Scripting # Why Scripting? # Many of the tasks that someone would like to perform on a computer are regular, require repetition, or are menial or tedious to do by hand. Shell scripting allows one to interact programmatically with a shell to do certain tasks. For example, the command for scanning log files in the previous topic guide could be automated to be performed on a schedule by means of a shell script. bash scripts are an incredibly powerful tool for sysadmins to automate tasks that are otherwise difficult to remember or long-running.\nIn cases where shell syntax is inappropriate for the task at hand, one can instead call into programs written in other languages, such as Python, which can read from stdin, process data, and write to stdout.\nBefore you jump into the assignment we reccomend reading through our Scripting Reference which provides a introduction to Bash and Python(optional part in this lab) scripting in Linux. Feel free to come back to this reference as you work through the assignment.\nScripting Lab Assignment # You\u0026rsquo;ll be completing a classic first shell scripting assignment: make a phonebook.\nWrite a shell script phonebook which has the following behavior:\n./phonebook new \u0026lt;name\u0026gt; \u0026lt;number\u0026gt; adds an entry to the phonebook. Don\u0026rsquo;t worry about duplicates (always add a new entry, even if the name is the same).\n./phonebook list displays every entry in the phonebook (in no particular order). If the phonebook has no entries, display phonebook is empty\n./phonebook remove \u0026lt;name\u0026gt; deletes all entries associated with that name. Do nothing if that name is not in the phonebook.\n./phonebook clear deletes the entire phonebook.\n./phonebook lookup \u0026lt;name\u0026gt; displays all phone number(s) associated with that name. You can assume all phone numbers are in the form ddd-ddd-dddd where d is a digit from 0-9.\nNOTE: You can print the name as well as the number for each line. For an additional challenge, try printing all phone numbers without their names. (See the example below for more details) For example,\n$ ./phonebook new \u0026#34;Linus Torvalds\u0026#34; 101-110-0111 $ ./phonebook list Linus Torvalds 101-110-1010 $ ./phonebook new \u0026#34;Tux Penguin\u0026#34; 555-666-7777 $ ./phonebook new \u0026#34;Linus Torvalds\u0026#34; 222-222-2222 $ ./phonebook list Linus Torvalds 101-110-1010 Tux Penguin 555-666-7777 Linus Torvalds 222-222-2222 # OPTIONAL BEHAVIOR $ ./phonebook lookup \u0026#34;Linus Torvalds\u0026#34; 101-110-1010 222-222-2222 # ALTERNATIVE BEHAVIOR $ ./phonebook lookup \u0026#34;Linus Torvalds\u0026#34; Linus Torvalds 101-110-1010 Linus Torvalds 222-222-2222 $ ./phonebook remove \u0026#34;Linus Torvalds\u0026#34; $ ./phonebook list Tux Penguin 555-666-7777 $ ./phonebook clear $ ./phonebook list phonebook is empty If you run into an edge case that isn\u0026rsquo;t described here, you can handle it however you wish (or don\u0026rsquo;t handle it at all). You can assume all inputs are in the correct format.\nSkeleton Code # To help you in this task, skeleton code for this lab can be found here. Once you are done with this task, you can submit your work on Gradescope.\nAs an optional (but recommended) assignment: Try implementing the same Phonebook behavior, but in python! This will highlight some of the strengths and weaknesses between the two languages. If you\u0026rsquo;re already familiar with python, you may find it helpful to do this before implementing it in bash.\nSome tips to make things easier # bash has an append operator \u0026gt;\u0026gt; which, as you might guess, appends the data from its first argument to the end of the second argument. $ cat foobar.txt foobar $ echo \u0026#34;hello, reader\u0026#34; \u0026gt;\u0026gt; foobar.txt $ cat foobar.txt foobar hello, reader bash also has a redirect operator \u0026gt;, which takes the output of one command and outputs it to a file. $ cat foobar.txt foobar $ echo \u0026#34;hello\u0026#34; \u0026gt; foobar.txt $ cat foobar.txt hello $ \u0026gt; foobar.txt $ cat foobar.txt $ Remember that you can simply write to and read from a file to persist data. In bash, changing lines can be done through the sed command. If you wish to do so, the format sed -i \u0026quot;s/\u0026lt;old\u0026gt;/\u0026lt;new\u0026gt;/g\u0026quot; ./filename may be helpful in this lab (e.g. for deleting a line or part of a line). For example: $ echo \u0026#34;hello 123\u0026#34; \u0026gt; foobar.txt # writes hello to foobar.txt $ cat foobar.txt hello 123 $ sed -i \u0026#34;s/h/j/g\u0026#34; foobar.txt $ cat foobar.txt jello 123 # You can also use regex: learn more at regex101.com $ sed -i \u0026#34;s/[0-9]\\{3\\}/world/g\u0026#34; foobar.txt $ cat foobar.txt jello world Recall that bash exposes its command line arguments through the $\u0026lt;integer\u0026gt; positional parameters: #!/bin/bash # contents of argscript.sh echo \u0026#34;$1\u0026#34; echo \u0026#34;$2\u0026#34; $ ./argscript.sh foo bar foo bar In bash, single quotes '' preserve the literal value of the characters they enclose. Double quotes \u0026quot;\u0026quot; preserve the literal value of all characters except for $, backticks `, and the backslash \\\\. The most important implication of this is that double quotes allow for variable interpolation, while single quotes do not. You can think of single quotes and the stronger \u0026ldquo;escape everything\u0026rdquo; syntax while double quotes are the more lax \u0026ldquo;escape most things\u0026rdquo; syntax. $ echo \u0026#39;$LANG\u0026#39; $LANG $ echo \u0026#34;$LANG\u0026#34; en_US.UTF-8 In python, you can interact with command-line arguments through the sys.argv list # !/usr/bin/python # contents of argscript.py import sys print(sys.argv[1]) print(sys.argv[2]) # end of file $ ./argscript.py foo bar foo bar python lets you manipulate files with the open function, commonly used with the with control structure # !/usr/bin/python # contents of fileman.py with open(\u0026#39;./newfile.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#34;hello from python\\n\u0026#34;) # end of file $ python fileman.py $ cat newfile.txt hello from python If you are getting permission denied issues, you will probably need to make your phonebook.sh executable: chmod +x phonebook.sh Submitting the lab # Once you\u0026rsquo;re done remember to submit your answers to Gradescope. There are multiple valid answers for some of the questions.\nFor the scripting assignment, you will need to upload a file containing your script. If you edit and test your script in your VM using vim or another shell editor, you can copy the file to your local machine using scp or simply copy-paste the text into a local file.\nDon\u0026rsquo;t be stressed about getting something correct; just have fun exploring.We\u0026rsquo;ll release the answers after the lab is due!\nAdditional Resources # Keybindings\nLearning vim progressively\nTmux cheat sheet\n"},{"id":5,"href":"/announcements/week-2/","title":"Week 2","section":"Announcements","content":"Hi everyone, we\u0026rsquo;re entering the second week of the DeCal! At this point, you should have turned in your Lab 1 on Gradescope. We’ll be taking a look and grading them soon. Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 02/11 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 2 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 2 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":6,"href":"/labs/3/","title":"Lab 3 - Packages and Packaging","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} About This Lab # Grading note # Labs are graded on completion. Treat this lab as seeds of exploration instead of just a grade.\nWorkflow # This lab should be completed on your Linux VM, and not on tsunami. You may need root access for part of the lab.\nDebian: An introduction to apt and dpkg # In this class, we will be focused on using Debian. As noted within this week\u0026rsquo;s lecture, Debian uses apt/dpkg as its package manager. Other distributions use different package managers.\napt # The frontend package manager for Debian is apt. For the majority of times when you need to deal with a package manager, apt is usually the way to go. Before doing anything with apt, it is typically a good habit to update the package list so that the package manager can find and fetch the most updated versions of various packages. To do that, you can run:\napt update\nTo find a package to install:\napt search [package|description]\nTo install a package:\napt install [package]\nTo remove a package:\napt remove [package]\nOnce you have been using the packages that you installed for a while, you may notice that they don\u0026rsquo;t automatically update themselves, a feature that may be present on programs written for other operating systems. To update the packages that you have installed, run:\napt upgrade or sometimes apt dist-upgrade\nIt is more commonplace to use apt upgrade to update your packages, but there are times when you need to use apt dist-upgrade. You can read up more about the differences between the two here.\nIn some circumstances, you want to be absolutely sure of the version of the package that you want to install. To list the potential versions that you can install, you can run:\napt policy [package]\nThis lists the candidate version to install, according to its pin priority, along with other versions that are compatible with the system. To install a a version for a specific target release, you can run:\napt -t [targetrelease] install [package]\nThere are also other commands that can remove unneeded dependencies and purge packages, but that is what the man pages are for. Please note that you are going to have to use sudo for the above commands since you are actually modifying the system itself.\ndpkg # The backend package manager is dpkg. Traditionally, dpkg is used to install local packages. Using dpkg, you also can inspect packages and fix broken installs. To install local packages, run:\ndpkg -i [packagefilename]\nTo remove a system package:\ndpkg --remove [package]\nTo inspect a package for more information about the package:\ndpkg -I [packagefilename]\nTo fix/configure all unpacked but unfinished installs:\ndpkg --configure -a\nGetting Started # We are going to use gcc to compile source code and a simple utility called fpm to create packages in this lab.\nUsing the commands above, install gcc, make, ruby-dev, and ruby-ffi.\nNow check if GCC and Ruby are installed by typing the followng:\ngcc --version\nruby --version\nNow install fpm using gem, Ruby’s own package manager:\nsudo gem install fpm\nNow check if fpm is installed:\nfpm\nNow clone the decal-labs repository:\ngit clone https://github.com/0xcf/decal-labs.git\nExercise 1: Compiling and Packaging # Packaging manually for Debian can be very hard and frustrating, especially for first timers. That’s why for this class, we’ll be using a really cool Ruby package called fpm which simplifies the task of packaging a lot.\nNote: This method is a great way to backport or package your own applications extremely quickly, but is not up to the more formal standards set by the Debian New Maintainers\u0026rsquo; Guide. If you\u0026rsquo;re up for a challenge, feel free to try following the lab instructions, but using the guidelines here for dpkg-buildpackage instead of using fpm.\nNow we will create a simplistic package using the hellopenguin executable that you will make in the coming steps. First, move into the lab 3 folder in the repository that you cloned in the Getting Started section:\ncd decal-labs/3\nNow we are going to create a folder to work in for this exercise:\nmkdir ex1\nAnd now move into the folder:\ncd ex1\nWriting and Compiling the Program # Now, we will make a very simple application in C that prints “Hello Penguin!” named hellopenguin. Invoke:\ntouch hellopenguin.c\nThis will create an empty file named hellopenguin.c. Now, using the a preferred text editor of your choice, such as vim, emacs, or nano, insert the following code into hellopenguin.c\n#include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello Penguin!\\n\u0026#34;); return 0; } We will now compile the source file that you have just written:\ngcc hellopenguin.c -o hellopenguin\nWhat this does is to take in a source file hellopenguin.c and compile it to an executable named hellopenguin with the -o output flag.\nPackaging the executable # Now, we will create the folder structure of where the executable shall reside in. In Debian, user-level packages usually reside in the folder /usr/bin/:\nmkdir -p packpenguin/usr/bin\nNow move your compiled hellopenguin exectuable into the packpenguin/usr/bin/ folder.\nmv hellopenguin packpenguin/usr/bin/\nNow we will create a package called hellopenguin. Move into the parent directory of the packpenguin folder and invoke the following:\nfpm -s dir -t deb -n hellopenguin -v 1.0~ocf1 -C packpenguin\nThis specifies that you want to take in a directory, using the -s flag, and to output a .deb package using the -t flag. It takes in a directory called packpenguin, using the -C flag, and output a .deb file named hellopenguin, using the -n, with a version number of 1.0~ocf1, using the -v flag.\nNow test it by invoking apt and installing it:\nsudo dpkg -i ./hellopenguin_1.0~ocf1_amd64.deb\nNote: For m1 users, the package might be hellopenguin_1.0~ocf1_arm64.deb\nNow you should be able to run hellopenguin by doing the following:\nhellopenguin\nExercise 2: Troubleshooting # Now we are going to try and troubleshoot a package. Move to the other folder, ex2.\nTry installing the ocfspy package using dpkg. It should error. Take note what it is erroring on! Now try and fix it.\nHint: Inspect the package for more details. The file to create that application is in the folder. Try compiling and packaging it. Exercise 1 may be a useful reference if you are stuck.\nAfter you’re done, complete the following questions and made a submission to Gradescope.\nCompiling and packaging\nWill we still be able to run \u0026ldquo;hellopenguin\u0026rdquo; from any directory if we packaged it into \u0026ldquo;/usr/share\u0026rdquo; instead of \u0026ldquo;/usr/bin\u0026rdquo;? What is your rationale for the previous answer? Debugging\nWhat package was missing after trying to install ocfspy? What is the password that ocfspy outputs after fixing the dependency problem? Note that you may want to clean up your VM by removing hellopenguin, ocfdocs, and ocfspy from your system.\nExercise 3: Spelunking # Let\u0026rsquo;s shift gears a bit and take a look at a popular package to learn more about how it\u0026rsquo;s structured! If you recall from lecture, we took at look at the contents of htop. For this next section, choose another package from the Debian repository to download and extract. You can choose any package that you\u0026rsquo;ve used/installed before (such as tmux, sl, or tree), or one from this list.\nNote that this exercise is mainly for exploration and learning purposes- you wouldn\u0026rsquo;t actually install a package using this method.\nOnce you\u0026rsquo;ve extracted the files (using the method shown in lecture), answer the following questions on Gradescope:\nWhat package did you choose? What are the package\u0026rsquo;s dependencies? What file can you find them in? Extract data.tar.gz and view its contents. If there exists a folder(s) other than usr/bin/ and usr/share/, pick one and briefly describe its purpose (both generally and in the context of this package). If not, explain why additional folders are not needed for this package. What\u0026rsquo;s one other interesting thing you learned about this package? (Binaries you never knew existed, easter eggs in documentation, a cool pre-install script\u0026hellip;) Hints:\nThe command to download a package is apt download \u0026lt;packagename\u0026gt;. To use aunpack, you might need to sudo apt install atool. Try to choose a package with a smaller filesize, so you won\u0026rsquo;t have to wait long for it to download and extract. The lecture demo will be quite helpful! You may want to watch it again for reference. For Hotshots # In the past examples, we have always precompiled a given program before packaging it. One upside to this, is that the package will always work for systems similar to the one that you run. However, once we start introducing other machines with potentially different architectures, we suddenly need to create duplicate packages compiled specifically for those systems. Create a new package that unpacks the source code for a file, compiles it, moves all of the relevant files to their respective locations, before deleting the irrelevant files.\nResources # Below are some resources that I found helpful in the creation of this lab. If you are feeling adventurous, you may want to poke around these documents as well.\nfpm\nTLDR pages, a more readable man page\ndpkg, alternatively man dpkg\napt, alternatively man apt\nDebian New Maintainers\u0026rsquo; Guide\n"},{"id":7,"href":"/announcements/week-3/","title":"Week 3","section":"Announcements","content":"Hi! Hope everyone\u0026rsquo;s had a good Presidential day weekend! we\u0026rsquo;re entering the third week of the DeCal. At this point, you should have turned in your Lab 2 on Gradescope. We know some people have been struggling with permissions on the Decal VM, and we\u0026rsquo;re looking into the issue. Let us know if this is happening to you on Edstem or through email and you\u0026rsquo;re allowed to submit late! Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 02/18 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 3 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 3 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":8,"href":"/labs/4/","title":"Lab 4 - Processes and Services","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Overview # For this lab, we are going to dive into processes and systemd. We will do this by writing our own systemd service from scratch, while showing the benefits of running a service with systemd. This lab should be completed on your Linux VM.\nPart 0: Set up networking # Before you start this lab, you\u0026rsquo;ll need to make sure you can access services from your VM in your web browser!\nOur VMs support IPv6 only, so you will need to connect to the campus GlobalProtect VPN first if you don\u0026rsquo;t have IPv6 connectivity.\nPart 1: Using systemd # What services are running right now? # Run systemctl. You\u0026rsquo;ll see a long table of every unit known to systemd. Let\u0026rsquo;s narrow it down to services for now. Run systemctl --type=service. Now you can see a list of all services running on your computer. Each of these services is a daemon running in the background. Do you see any familiar services running?\nQuestion 1: What is the name of a systemd service running on your system? What does it do? (If you\u0026rsquo;re not sure what it does, Google it!)\nControlling Services # Now let\u0026rsquo;s use systemd to control a an nginx web server. If you don\u0026rsquo;t have it already, install nginx by issuing sudo apt install nginx. Once that is done we can tell systemd to start the service with the following: sudo systemctl start nginx. Run systemctl status nginx to ensure it is running.\nNote: If you already have a webserver running, you may need to shut it down, so that port 80 is available for nginx to use.\nNow let\u0026rsquo;s make nginx listen for connections on the nonstandard port 420. In /etc/nginx/sites-available/default change the following lines:\nlisten 80 default_server; listen [::]:80 default_server; to:\nlisten 420 default_server; listen [::]:420 default_server; TIP: The first line configures the server to listen on IPv4, and the second line configures IPv6.\nTell systemd that nginx has changed configuration and needs reloading with: sudo systemctl reload nginx.\nNow, accessing http://[yourusername].decal.ocfhosted.com:80 should now give you a connection refused error and your webserver will only be accessible via http://[yourusername].decal.ocfhosted.com:420.\nNote that not all services can be reloaded; systemd will notify you if this is the case and such services will have to be restarted instead with: sudo systemctl restart yourservice.\nFinally go ahead and stop the nginx service with sudo systemctl stop nginx.\nQuestion 2: What is the difference between systemctl reload yourservice and systemctl restart yourservice?\nQuestion 3: Upload a screenshot of your browser accessing the nginx webserver at http://[yourusername].decal.ocfhosted.com:420. Note: If you can\u0026rsquo;t access the IPv6 site use curl localhost:420 on the VM and paste it\u0026rsquo;s contents (it should be a html page).\nCreating a service # Let\u0026rsquo;s set up a web server and create a systemd unit for it. Make sure git is installed; if it\u0026rsquo;s not, install it using apt.\nIf you don\u0026rsquo;t already have the decal-labs repo from a past lab, run the following:\n$ git clone https://github.com/ocf/decal-labs The materials for this part of the lab will be in the decal-labs/4 directory. We will also need to install some dependencies. Go ahead and execute the following commands:\n# apt update # apt install build-essential make python3-virtualenv Now run ./run. This should start up a simple web server at http://localhost:5000. Note that by default you can only access the web server on the VM itself.\nYour mission, should you choose to accept it, is to write a systemd service that manages this web server. To do this, make a new unit file in /etc/systemd/system/toy.service. Refer to the slides for an example; DigitalOcean also has a good guide on how to write systemd units. Here is a skeleton; all you need to do is fill in the values for each field.\n[Unit] Description= Requires= After= [Install] WantedBy=multi-user.target [Service] ExecStart= User= Some questions worth considering while writing this unit file are:\nWhat units needs to be started before a webserver starts? (Hint: you can get a list of special \u0026ldquo;target\u0026rdquo; units using systemctl --type=target.) What script should systemd run to start the webserver? (Remember you\u0026rsquo;ll need to use the absolute path of the script, not the relative one. You can find this by running realpath -se \u0026lt;path to script\u0026gt;.) Units run by root as default. Is that a safe practice for web servers? You are encouraged to experiment with other fields as suits your liking. Once you have finished creating toy.service, let\u0026rsquo;s start the service and have the it start whenever our machine is booted.\n# systemctl start toy.service # systemctl enable toy.service Debugging # You can check if the unit file succeeded by running systemctl status toy.service. If you are having issues with the unit file or the web server, check the logs for this unit by running journalctl -u toy.service. If you run into errors don\u0026rsquo;t get demoralized (it is, after all, only a decal); as a sysadmin you\u0026rsquo;ll have to become comfortable making sense of arcane error messages.\nTIP: You can omit the .service in systemctl command for speed. If the unit is another type (e.g. target, socket, or timer), you must include the type. We include the .service for clarity.\nCrash the service! # One of the great benefits of using systemd to manage your services is that you don\u0026rsquo;t have to worry unnecessarily about bringing a process back up if it crashes. So let\u0026rsquo;s crash the service! You can do this by either sending a POST request with the json payload {\u0026quot;crash\u0026quot;:\u0026quot;true\u0026quot;} to http://localhost:5000/crash on the VM (Hint: use cURL) or by killing the webserver manually by sending a signal \u0026ndash; both will cause the unit to crash. You can verify if you succeeded by running systemctl status toy.service, and the unit should either be in an inactive or failed state, depending on how you killed it.\nQuestion 4: What command did you run to crash the service?\nNow add the following the /etc/systemd/system/toy.service under the Service directive:\nRestart=always RestartSec=10 To tell systemd that the unit file has changed run sudo systemctl daemon-reload. Now start your webserver and crash it again in any way you please, and you should see that it come back online after 10 seconds! Note that you can also run daemon-reload and change a unit file while a service is running.\nQuestion 5: Upload your fully featured toy.service file to Gradescope.\nPart 2: Processes # There are no Gradescope questions to answer for this section, but you should still go through the steps to make sure you understand processes and how to use htop!\nOpen up a terminal and run the ps command. You should see something like this:\nPID TTY TIME CMD 3371 pts/2 00:00:00 zsh 3416 pts/2 00:00:00 ps Now open up another terminal and run sleep 1000 \u0026amp;, which start a sleeping process in the background. Then run ps. It should look like:\n~ ❯ sleep 100 \u0026amp; [1] 3726 ~ ❯ ps PID TTY TIME CMD 3371 pts/2 00:00:00 zsh 3726 pts/2 00:00:00 sleep 3752 pts/2 00:00:00 ps In the first terminal run ps again. You should notice that the sleep process is not showing up, even though the thousand seconds haven’t expired.\nWhy do you think this behavior occurs (hint: TTY column)?\nWe can get the process to display on the first terminal by running ps -u, which displays all the processes running as your user. Notice the PID column; each process has a unique ID assigned to it by the kernel. One thing we can do with this PID is send signals to the process. sleep 1000 is pretty useless, so go ahead and kill it – kill 3726 (substitute 3726 with whatever PID ps outputted for you).\nThe most common use of ps is to run ps -ef to see all the processes running on the system. Run ps -e and ps -f independently to see how the flags work together.\nhtop # Make sure htop is installed by running sudo apt install htop. Now, open up a terminal and run the htop command. htop can be thought of as a more extensive version of ps -ef, whereby process stats are updated in real-time.\nFirst press \u0026lt;F2\u0026gt;, scroll down to Display options, and check “Hide userland process threads.” We won’t be dealing with those in this lab.\nNow open up another terminal (or use tmux). Run the command yes. It uses a lot of resources as it prints a continuous stream of y’s.\nWhat resource specifically does the yes command exhaust? If you are having trouble finding this, press \u0026lt; to choose which resource to order processes by. Make sure to quit out of yes (^C) once you are finished.\nThe process hierarchy # Run htop once more. This time click \u0026lt;F5\u0026gt; to enter Tree View. You should see a visual representation of the process hierarchy on your system, with everything stemming from /sbin/init (systemd).\nFor curious students that are interested in seeing a more extensive process hierarchy on a large system, you are encouraged to run htop on the OCF server tsunami. Let us know of any cool processes that you find!\nOrphan processes # Open a second terminal and ssh to your VM. Now run sleep 1000 \u0026amp;. You should see this new process pop into your htop session on your first terminal. If not, press \u0026lt;F3\u0026gt; and search for “sleep.” What is its parent?\nSelect this parent and press \u0026lt;F9\u0026gt; to kill it. Send the SIGTERM signal. The sleep process now has init as its new parent, which is PID 1. What you just did is manually orphan a process; when that happens said process is subsequently re-parented by the init process.\nNow go through the same steps again. This time, send the parent a SIGHUP (hangup) signal. Can you still find the sleep process? When SIGHUP is sent to a parent shell, the parent subsequently sends hangup signals to any child processes before terminating; all processes that receive SIGHUP from a parent shell will terminate – this is one way to avoid creating orphan processes.\nIf you are interested in learning about the different signals, run man 7 signal. Note that you can run man man for an explanation about the different manual section numbers.\nExploration # Congratulations, you have completed the lab! This is just the tip of the iceberg when it comes to processes and services. If you want to learn more, here are some related topics you can look into.\nWikipedia\u0026rsquo;s article on init systems The construction of a basic init system Yelp\u0026rsquo;s dumb-init, a lightweight init system for docker containers Zombie Processes Socket activation Systemd has been the source of a considerable amount of controversy. Opponents allege that it violates the Unix philosophy of “do one thing and do it well”, and that it has had too much scope creep, among other complaints. Everything you wanted to know about Unix threads, processes, process groups and sessions. Bear in mind that this document is a little dated when it comes to the code about threads, and its description of what happens when a pseudotty is closed is not actually correct. Submission # Go to Gradescope to submit your answers!\n"},{"id":9,"href":"/staff/","title":"Staff","section":"Home","content":" Staff # Communication # Official course communications will primarily be sent via email and mirrored on the front page of the course website.\nThere are several ways you can get in contact with course facilitators:\nMake a post on Ed. (best for conceptual/debugging/content help) Send a message to #decal-general (or as a private message to a facilitator) either on Slack or Discord. (best for realtime communications) Email decal@ocf.berkeley.edu. (best for prospective students and matters that need to go on official record) See the about page for more information.\nHead Facilitators # Carl Luo\nerdaifuu@ocf.berkeley.edu\n(^ω^) （╹◡╹） :3\nSawan Srivastava # # Facilitators # "},{"id":10,"href":"/announcements/week-4/","title":"Week 4","section":"Announcements","content":"Hi everyone, we\u0026rsquo;re entering the fourth week of the DeCal! At this point, you should have turned in your Lab 3 on Gradescope. We’ll be taking a look and grading them soon. Lab 1 and 2 grades have also been released! Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 02/25 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 4 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 4 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":11,"href":"/labs/5/","title":"Lab 5 - Introduction to Networking","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Overview # It is undeniable that the internet is an important system that has redefined our world. The ability to develop networks and allow devices to communicate is critical to modern day computer systems. This lab will take a look into the basics of computer networking and then examine networks through the perspective of a sysadmin.\nWe will be using web browsing as an analogy to understand the basics of networking. What exactly happens when I go web browsing for cat pictures?\nBut first let\u0026rsquo;s take a short dive into the details of networking.\nMAC # Media access control (MAC) addresses are identifiers uniquely assigned to network interfaces. Since the MAC address is unique this is often referred to as the physical address. The octets are often written in hexadecimal and delimited by colons. An example MAC address is 00:14:22:01:23:45. Note that the first 3 octets refer to the Organizationally Unique Identifier (OUI) which can help identify manufacturers. Fun fact \u0026ndash; the 00:14:22 above is an OUI for Dell.\nIP # IP addresses are means of identifying devices connected to a network under Internet Protocol. There are two versions of the internet protocol, IPv4 and IPv6, that which differ on the size of their addresses. An example IPv6 address is 2001:0db8:85a3:0000:0000:8a2e:0370:7334 which is considerably longer than an IPv4 address like 127.0.0.1. For the sake of time we will only go over IPv4, but IPv6 is certainly gaining ground and worth checking out!\nIPv4 addresses are 32 bits, i.e. 4 bytes, long and are delimited by a dot (.) every byte. An example IPv4 address is 127.0.0.1. Coincidentally this address is known as the loopback address which maps to the loopback interface on your own machine. This allows network applications to communicate with one another if they are running on the same machine, in this case your machine. But why 127.0.0.1 and not 127.0.0.0 or 127.0.0.2?\nThe answer is that 127.0.0.1 is simply convention, but technically any address in the network block 127.0.0.0/8 is a valid loopback address. But what exactly is a network block?\nIn IPv4 we can partition a block of addresses into a subnet. This is written in a format known as CIDR. Let\u0026rsquo;s take the subnet above as an example 127.0.0.0/8. The number that comes after the slash (/), in this case 8, is the subnet mask. This represents how many bits are in the network address, the remaining bits identify a host within the network. In this case the network address is 127.0.0.0 and the Mask is 255.0.0.0. So 127.0.0.1 would be the first host in the 127.0.0.0/8 network and so on and so forth.\nThis diagram provides a visual breakdown of CIDR addressing ARP # Address Resolution Protocol (ARP) is a protocol used to resolve IP addresses to MAC addresses. In order to understand ARP, we first discuss two ways to send a frame, unicast and broadcast. In the context of Layer 2, unicasting a frame means to send that frame to exactly one MAC address. On the other hand, broadcasting a frame by sending it to the broadcast address means the frame should be sent to every device on the network, effectively \u0026ldquo;flooding\u0026rdquo; the local network.\nFor example let\u0026rsquo;s imagine a sender, A, who has MAC 00:DE:AD:BE:EF:00, broadcasting a message that essentially asks \u0026ldquo;Who has IP address 42.42.42.42 please tell A at 00:DE:AD:BE:EF:00\u0026rdquo;.\nIf a machine, B, with MAC 12:34:56:78:9a:bc has the IP address 42.42.42.42 they send a unicast reply back to the sender with the info \u0026ldquo;12:34:56:78:9a:bc has 42.42.42.42\u0026rdquo;. The sender stores this information in an ARP table so whenever it receives packets meant for machine B i.e. a packet with an destination IP address of 42.42.42.42 it sends the packet to MAC it received from B.\nIn order to route IP packets, devices have what is known as a routing table. Routing entries are stored in the routing table and they are essentially rules that tell the device how packets should be forwarded based on IP. A routing entry specifies a subnet and the interface that corresponds to that entry. The device chooses an entry with a subnet that is most specific to a given packet and forwards it out the interface on that entry.\nRouting tables are usually to also have a default gateway. This serves as the default catch all for packets in the absence of a more specific matching entry.\nTake this routing table for example.\ndefault via 10.0.2.2 dev eth0 10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 10.0.2.128/25 dev eth0 proto kernel scope link src 10.0.2.15 192.168.162.0/24 dev eth1 proto kernel scope link src 192.168.162.162 A packet destined for 8.8.8.8 would be forwarded out eth0, the default gateway.\nA packet destined for 10.0.2.1 would be forwarded according to the second entry, out of eth0.\nA packet destined for 10.0.2.254 would be forwarded according to the third entry, out of eth0.\nA packet destined for 192.168.162.254 would be forwarded according to the fourth entry, out of eth1.\nDNS # We\u0026rsquo;ve gone over IP addresses and how they are means of communicating with a host over IP, but while IP addresses are machine friendly (computers love numbers) they aren\u0026rsquo;t exactly human friendly. It\u0026rsquo;s hard enough trying to remember phone numbers, memorizing 32 bit IP addresses isn\u0026rsquo;t going to be any easier.\nBut it\u0026rsquo;s much easier for us to remember names like www.google.com, www.facebook.com, or coolmath-games.com. So out of this conflict the Domain Name System (DNS) was born as a compromise between machine friendly IP addresses and human friendly domain names.\nDNS is a system that maps a domain name like google.com to 172.217.6.78. When you query for google.com your computer sends out a DNS query for google.com to a DNS server. Assuming things are properly configured and google.com has a valid corresponding address you will receive a response from an authoritative server that essentially says \u0026ldquo;google.com has IP address x.x.x.x\u0026rdquo;.\nNow let\u0026rsquo;s flush out this black magic a bit\u0026hellip;\nDNS Records # DNS servers store data in the form of Resource Records (RR). Resource records are essentially a tuple of (name, value, type, TTL). TTL stands for \u0026ldquo;Time to Live\u0026rdquo; and represents the duration of time (in seconds) a DNS Record may be cached for. While there are a wide variety of types of DNS Records, the ones we are most concerned with are:\nA records name = hostname value = IP address\nThis record is very simply the record that has the IP address for a given hostname, essentially the information we want to end up with.\nNS records\nname = domain\nvalue = name of dns server for domain\nThis record points to another dns server that can provide an authoritative answer for the domain. Think of this as redirecting you to another nameserver.\nCNAME records\nname = alias\nvalue = canonical name\nThese records point to the canonical name for a given alias for example docs.google.com would be an alias which simply points to documents.google.com try www.facebook.com\nMX records The record used by mail service.\nTCP and UDP # Now we will transition into a discussion on the protocols at the transport layer. The two most well known protocols at this layer are Transmission Control Protocol (TCP) and User Datagram Protocol (UDP).\nTCP is a stateful stream oriented protocol that ensures reliable transport. Reliable transport essentially guarantees that information arrives wholly intact and in order at the destination.\nTCP is a connection oriented protocol which means it must first establish a connection before sending any data. This connection exchanges information that is the mechanisms TCP uses to provide reliable transport amongst other features. A TCP connection begins with something known as the TCP handshake.\nThe TCP handshake consists of setting certain flags in the TCP header of packets exchanged between sender and receiver. The sender initiating a TCP connection by first sending a SYN, a packet with the SYN flag set. The server acknowledges this connection request by sending back a SYN-ACK, a packet with both the SYN and ACK flags set. The client acknowledges this by sending one final ACK back to the server, and the connection is then established.\nTCP then begins transmitting data and if it successfully arrives on the other end of the connection then an ACK is issued. Therefore if data is lost, reordered, or corrupted, TCP is capable of recognizing this and sends a request for retransmission of any lost data.\nTCP also has a procedure to close connections. We only consider a graceful termination here, abrupt terminations have a different procedure we will not go over. If you\u0026rsquo;re interested, CS168 has some great material here. Let\u0026rsquo;s assume machine A wants to close its connection to machine B.\nA begins by sending a FIN. B must respond by sending a FIN and an ACK. If B only sends a ACK the connection persist and additional data can be sent until an FIN is sent. On the other hand B can also send just one packet with both FIN and ACK flags set, i.e. FIN+ACK if B is ready to close the connection and doesn\u0026rsquo;t need to send additional data Once A has received a FIN and an ACK it sends one last ACK to signal the connection termination.\nUDP is stateless connectionless protocol. UDP focuses on sending messages in datagrams. Being connectionless UDP also doesn\u0026rsquo;t incur the overhead of the TCP handshake and termination. UDP also makes no guarantees about reliable transport so messages may be corrupted, arrive out of order, or not arrive at all. For this reason UDP is sometimes called Unreliable Datagram Protocol.\nWhile UDP makes no guarantees about reliable transport it doesn\u0026rsquo;t suffer from the overhead of establishing and closing connections like in TCP. UDP is therefore ideal for usage cases where we just want to send packets quickly and losing a few of those isn\u0026rsquo;t disastrous.\nMoreover, compared to TCP each UDP datagram sent needs to be individually received. While for TCP you pass a stream of data that is transparently split into some number of sends and the data stream is transparently reconstructed as a whole on the other end.\nPorts (Optional) # Ports define a service endpoint, broadly speaking \u0026ndash; ports mark a point of traffic ingress and egress. Whereas IP addresses connect hosts, ports connect process that run on such hosts. Only one process can be bound to a port at a time. Ports are represented by a 16 bit number meaning thus ranging from 0 to 65535. Ports from 0 to 1023 are well known ports, i.e. system ports. Using these ports usually has a stricter requirement. 1024 to 49151 are registered ports. IANA maintains the official list of well-known and registered ranges. The remaining ports from 49152 to 65535 are ephemeral ports which can be dynamically allocated for communication sessions on a per request basis.\nSome port numbers for well known services are as follows:\nService Port SSH 22 DNS 53 HTTP 80 HTTPS 443 Sysadmin Commands # As a sysadmin, trying to diagnose network issues can often be pretty challenging. Given the scale and complexity of networks, it\u0026rsquo;s tough trying to narrow down the scope of a problem to a point of failure. What follows is a list of commands/tools that can help with triaging problems. There are a lot of tools and we don\u0026rsquo;t expect you to memorize every single detail. However, it is important to know what tools exist and when to use them when problems inevitably arise. If you ever need more details the man pages for these commands are a great place to turn to for reference.\nTools also tend to overlap in functionality \u0026ndash; for example there are multiple tools that can display interface information or test connectivity. When possible, it is a good idea to use multiple tools to cross-check one another.\nNote that when it comes to real world networks there are even more factors to consider that we haven\u0026rsquo;t touched on like network security. For example, two machines can have a fully functioning connection but if one machine has been configured to drop all packets then it might seem as if they aren\u0026rsquo;t connected.\nSo take the output of these tools with a grain of salt, they a means of narrowing down issues. It is important not to misinterpret outputs or jump to conclusions too quickly.\nhostname A simple and straightforward command that can display information about a host, IP addresses, FQDN, and etc. Make sure to also check out host, which is a similar command that provides more detailed information by doing a lookup on a given name.\nping Another simple command, most of the time you\u0026rsquo;ll be using ping as a first step towards testing connectivity. If ping can\u0026rsquo;t reach a host then there is likely an issue with connectivity. The ping tool does this by sending out ICMP messages to the host expecting a response. (More on the protocol here)\nMoreover ping also provides metrics for Round Trip Time (RTT) and packet loss. Round trip time is defined as the time it takes for a response to arrive after sending the ping packet. These can prove to be very useful statistics.\ntraceroute Traceroute sends packets Time to Live (TTL) equal to the number of hops. Routers decrease the value of TTL for incoming packets. If a packet\u0026rsquo;s TTL = 0 then the router drops it and may send back diagnostic information to the source about the router\u0026rsquo;s identity. Otherwise the router continues forwarding the packet.\nTraceroute provides a detailed view of the routers that a packet traverses while on its way to a destination.\nIf router does not respond within a timeout then traceroute prints an asterisk.\narp Provides info on and the ability to manipulate the ARP cache of the system.\nWith arp you can display the system arp table. Add, remove, or modify arp entries and much more.\ndig Utility for doing dns query and triaging DNS issues.\nDig by default performs queries to nameservers in /etc/resolv.conf but some options allow you to: specify name server, choose query type (iterative vs recursive), and much more \u0026ndash; making dig a very flexible DNS tool.\nip ip is a command with many subcommands offering a lot of functionality \u0026ndash; so much it can be overwhelming at first. You will most commonly be using ip to display/modify routing, IP addresses, or network interfaces.\nIt will take time to get use to how much functionality is included in this command but for reference here is a pretty compact cheatsheet. A few common use cases include: ip addr which displays information on your IP addresses, ip route which displays information on your routing table, and ip link which displays information about your network interfaces.\ncurl cURL does as its name suggests, and allows you to see the contents at certain URLs. Beyond this it\u0026rsquo;s also an extremely powerful program that lets you interact with and inspect servers over several different protocols certain protocols such as HTTP, FTP, etc \u0026hellip;\nBe sure to check out its documentation for specific use cases.\nwget wget is quite similar to curl in the sense that they are both command line tools designed to transfer data from or to servers with certain protocols and both come with a bunch of features.\nThere are differences between the commands, two notable examples being that wget is command line only meaning there no library or API. However, wget has a big advantage of being able to download recursively. You can read a bit more on the two tools here.\nnetstat (Optional) This tool is good for printing network connections, routing tables, and probing sockets, amongst other functions.\nnetstat also has functionality to probe sockets for activity and displays information such protocol (UDP/TCP)\nIf you are investigating sockets ss and lsof are also options you may want to consider\ntcpdump (Optional) Perfect for monitoring incoming or outgoing traffic on a machine.\ntcpdump offers countless options when it comes to analyzing traffic: it can capture packets, log traffic, compute metrics, filter traffic, monitor specific interfaces, etc. As a primer you can check out these examples.\nnc (Optional) Netcat is a very powerful tool that can be used for just about anything involving TCP or UDP. It can open TCP connections, send UDP packets, listen on arbitrary TCP and UDP ports, do port scanning, and deal with both IPv4 and IPv6.\nExercises # Short Answer Questions # Does HTTP use TCP or UDP and why? How about Discord and Skype, why? Who manufactured the NIC with mac address dc:fb:48:21:7b:23? How many distinct hosts can 127.0.0.0/8 contain? What are three types of records you can get when you perform a DNS lookup of google.com using the dig command? Is the result of running ping enough to determine whether or not you can reach a server? Why or why not? Programming Exercise # Write a shell script is_on.sh so that is_on.sh host shows whether host is online. If it is, show \u0026ldquo;OK\u0026rdquo;. If it\u0026rsquo;s not, show \u0026ldquo;Host is not reachable\u0026rdquo;. Don\u0026rsquo;t show anything else. Some clarifications:\nA host is online here means the ping to the host is successful Just ping the server once (we assume the internet connection is reliable and the packet will not be dropped) You can use man ping to see how to make the ping only ping the server once, and what the return value of ping command means. Use if to decide what to print. Write a shell script mac.sh which processes the output of ip command and displays the MAC address of the network interface ens3 of your VM.\nFirst figure out how to use ip command to get an output which contains the information we want Then use head and tail command and pipes to tailor ip\u0026rsquo;s output to one line Use cut command ( Examples) to get the MAC address. Since we know that the MAC address has fixed length, feel free to count the indices. The final shell script only has to have one line, although a answer with multiple lines are also acceptable. Submission # Go to Gradescope for submission.\n"},{"id":12,"href":"/announcements/week-5/","title":"Week 5","section":"Announcements","content":"Hi everyone, we\u0026rsquo;re entering week 5 of the DeCal! At this point, you should have turned in your Lab 4 on Gradescope. Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 03/04 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 5 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 5 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":13,"href":"/labs/6/","title":"Lab 6 - Web Servers","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Overview # Networking is key to many services because it allows processes and computers to communicate with each other. In this lab, we\u0026rsquo;ll explore different networked services with an emphasis on web services.\nMake sure that you are doing all of these steps on your VM.\nWhich networked services are already running? # There are multiple networked services running on your VM right now. To output the networked services running on the VM use netstat (install using apt).\nQuestion 1a: What command did you use to display the networked services? Question 1b: Paste the output of the command. Question 1c: Choose one service from the output and describe what it does. DNS # In this section we are going to be setting up our own DNS server! Remember that DNS is the system that maps from a domain like ocf.berkeley.edu to an IP like 169.229.226.23 (and 2607:f140:8801::1:23 for IPv6) so that computers know how to send information over the network to servers without people having to remember a bunch of numbers to connect to everything.\nFirst, install the bind9 package on your VM to set up a DNS server. Uninstall dnsmasq if it\u0026rsquo;s previously installed on your VM by sudo apt purge dnsmasq.\nLet\u0026rsquo;s check the status of the service using systemctl. What command can you run to do this?\nIn the output of the systemctl command, you should see that the bind9 service is already running. Let\u0026rsquo;s bring it down temporarily so we can investigate: systemctl stop bind9\nThe service should have a unit file at /lib/systemd/system/named.service or /lib/systemd/system/bind9.service. If you print that file (with cat or systemctl cat bind9), you should see something like this:\n[Unit] Description=BIND Domain Name Server Documentation=man:named(8) After=network.target Wants=nss-lookup.target Before=nss-lookup.target [Service] EnvironmentFile=-/etc/default/named ExecStart=/usr/sbin/named -f $OPTIONS ExecReload=/usr/sbin/rndc reload ExecStop=/usr/sbin/rndc stop [Install] WantedBy=multi-user.target Alias=bind9.service This should look somewhat familiar to you after the lecture on networking! Don\u0026rsquo;t worry if it doesn\u0026rsquo;t all look familiar since there are some options you haven\u0026rsquo;t seen yet in here, but you should at least recognize some of the options used.\nIf you now run dig ocf.berkeley.edu @localhost from your VM, you should see that the command eventually times out after trying to run for about 15 seconds. This is because it is trying to send DNS requests to your VM, but the DNS server is not actually running yet so it doesn\u0026rsquo;t get a response. However, if @localhost is left off the end of the command, it succeeds. Why is this the case? What DNS server are requests currently being sent to if @localhost is not specified in the command?\nTry starting the DNS server using the relevant systemctl command. If you check the status of the bind9 service after starting it, you should see the status has changed to say that the service is active and running.\nIf you now run dig ocf.berkeley.edu @localhost from your VM, you should now see a response containing the correct IP (169.229.226.23)!\nNow to the exciting part, the configuration! Edit /etc/bind/named.conf.local with your favorite text editor (add sudo if you don\u0026rsquo;t have write permission). Inside this file, it should be empty apart from a few comments at the top because you haven\u0026rsquo;t done any local configuration yet. Add a new zone in this file for example.com with these contents:\nzone \u0026#34;example.com\u0026#34; { type master; file \u0026#34;/etc/bind/db.example.com\u0026#34;; }; Then, create a file /etc/bind/db.example.com to contain the responses to give if anyone sends requests to your DNS server for example.com. The easiest way to do this is generally to copy an existing config and then make changes from there to get what you want for your config instead of having to start from scratch.\nTo make this easier, we\u0026rsquo;ve provided a valid config in decal-labs that you can copy in place at /etc/bind/db.example.com.\nLet\u0026rsquo;s start by adding a record for a subdomain named test.example.com.\nAdd the line below to /etc/bind/db.example.com.\ntest\tIN\tA\t93.184.216.34\nMake sure to reload the bind9 service after changing anything in /etc/bind9, since you want the running service to change its configuration.\nsystemctl reload bind9\nNow run the commands below. For the first command you should see the result for example.com which should be 1.2.3.4. For the second command you should see 93.184.216.34 as the result.\ndig @localhost example.com\ndig @localhost test.example.com\nPlease add few more records of your choice. Try to add one A record, and a couple of other types of records (CNAME, SRV, TXT, etc.). Make sure to reload the bind9 after!\nQuestion 2a: What is the systemctl command to show whether bind9 is running or not?\nQuestion 2b: Why does the dig command (dig ocf.berkeley.edu) work if @localhost is not present at the end (if bind9 is not started) but times out when @localhost is added?\nQuestion 2c: What additional entries did you add to your DNS server config (the db.example.com file)?\nQuestion 2d: What commands did you use to make requests to the local DNS server for your additional entries?\nLoad Balancing # For this section we will be using HAProxy, a commonly-used open-source load balancer. NGINX is actually starting to become a load balancer alongside being a web server, which is pretty interesting, but HAProxy is still commonly used.\nYou can install HAProxy using sudo apt install haproxy.\nFirst, grab the python file for the service you will be running from the decal-labs repo using wget or something similar to download it. You\u0026rsquo;ll likely also need to install tornado using sudo apt install python3-tornado.\nNext, run the script using python3 server.py.\nAfter running python3 server.py, the script will start up 6 different HTTP server workers listening on ports 8080 to 8085 (inclusive). Each worker returns different content to make it clear which one you are talking to for this lab (\u0026ldquo;Hello, I am ID 0\u0026rdquo; for instance), but in real usage they would generally all return the same content. You would still want something to distinguish between them (maybe a HTTP header saying which host or instance they are?), but only for debugging purposes, not like in this lab where they have actually differing content.\nYou can test out each worker if you\u0026rsquo;d like by making a request (e.g. using cURL) individually to each server (http://localhost:8080 to http://localhost:8085) on your VM.\nThe idea behind using a load balancer is that requests will be spread out among instances so that if a lot of requests are coming in all at once, they will not overload any one instance. Another very useful feature is that if one of the instances happens to crash or become unavailable for whatever reason, another working server will be used instead. This requires some kind of health checks to be implemented to decide whether a server is healthy or not.\nYour job is to do the configuration to get it to work with the services you are given! The main config file is at /etc/haproxy/haproxy.cfg and you should only have to append to the end of this file to finish this lab. One snippet is provided here for you to add to the config already, this will give you a nice status page that you can use to see which of the servers is up or down:\nlisten stats bind 0.0.0.0:7001 bind [::]:7001 mode http stats enable stats hide-version stats uri /stats After adding this, if you restart the haproxy service and open http://[yourusername].decal.ocfhosted.com:7001/stats in a web browser, you should see a page with a table and some statistics information on HAProxy (pid, sessions, bytes transferred, uptime, etc.).\nPart 1: Configuration # Your goal is to add a backend and frontend to haproxy\u0026rsquo;s config that proxies to all of the running workers on the ports from 8080 to 8085 and listens on port 7000 on your VM, so that if you go to http://[yourusername].decal.ocfhosted.com:7000 you can see the responses from the workers. Try refreshing, what do you notice happening? Do you notice a pattern? What load balancing algorithm are you using from your observations? What config did you add to the haproxy config file to get this to work? Try changing the algorithm and see what happens to your results!\nPart 2: Health Checks # Now, after adding all the servers to the backend in the config, add health checks for each of them. If you refresh the stats page, what do you notice has changed? What color are each of the servers in your backend?\nSome hints for Parts 1-2 # You shouldn\u0026rsquo;t need to change the current contents of haproxy.cfg; you\u0026rsquo;ll just need to append additional lines to the bottom of the file. You\u0026rsquo;ll need to add two sections, one for frontend and one for backend. Take a look at the Frontend and Backend sections of The Four Essential Sections of an HAProxy Configuration to learn more about the syntax and options available! You can label your frontend and backend sections however you wish. You should need to append about 10-15 lines to the config file. Make sure you include a line to listen for IPv6 requests in addition to IPv4 (bind [::]:\u0026lt;port number\u0026gt;) If you\u0026rsquo;d like more hints, feel free to ask on #decal-general! Part 3: Crashing # If you make a request to http://[yourusername].decal.ocfhosted.com:7000/crash, it will crash the worker that you connect to. What changes in the HAProxy stats page? (Try refreshing a few times, the health checks can take a couple seconds to update the status from UP -\u0026gt; DOWN) If you make a lot of requests to http://[yourusername].decal.ocfhosted.com:7000 again, are all the servers present in the IDs that are returned in your requests or not? Try crashing a particular worker by running curl localhost:\u0026lt;port\u0026gt;/crash on your VM, substituting the port with one of the workers that is still up on your instance. What happens on the HAProxy stats page? If you crash all the workers, what status code does HAProxy return to you when you make a request to the service?\nQuestion 3a: Do you notice any pattern when you refresh the page multiple times?\nQuestion 3b: What load balancing algorithm are you using?\nQuestion 3c: What did you add to the haproxy config? (just copy and paste the lines you added to the bottom into here)\nQuestion 3d: What do you notice has changed on the stats page after adding health checks? What color are each of the servers in the backend now?\nQuestion 3e: What changes in the stats page when you crash a worker? What happened to the pattern from before?\nQuestion 3f: What HTTP status code (or error message) does HAProxy return if you crash all of the workers?\nRemember to submit your answers on Gradescope!\n"},{"id":14,"href":"/announcements/week-6/","title":"Week 6","section":"Announcements","content":"Hi everyone, we\u0026rsquo;re entering week 6 of the DeCal! At this point, you should have turned in your Lab 5 on Gradescope. Regarding Lab 2 and 3 grades, Lab 2 grades should be released now, and Lab 3 is being graded, thank you for your patience! Weekly notes: \u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; HEAD\nNormal schedule, Lecture + Lab on Tuesday 03/11 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 6 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 6 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":15,"href":"/labs/7/","title":"Lab 7 - Security Fundamentals","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} For this lab, we will use GnuPG (also referred to as GPG), a free implementation of the OpenPGP standard. As stated by GPG\u0026rsquo;s website:\nGnuPG allows you to encrypt and sign your data and communications; it features a versatile key management system, along with access modules for all kinds of public key directories.\nThe GPG manual page might be useful.\nEncryption and Decryption # Encryption takes in a plaintext and a key, returning ciphertext. Decryption takes in a ciphertext and a key, recovering and returning the original plaintext only if the decryption key is valid. The keys for encryption and decryption are long strings of random bits that make it computationally infeasible for an attacker to guess the key and decrypt a ciphertext.\nSymmetric Cryptography # In symmetric cryptography, the keys used for encryption and decryption are the same.\nTo try it out:\ngpg --symmetric [FILE] on any file to output a [FILE].gpg file which is the encrypted version of the inputted file. You\u0026rsquo;ll need to enter a password when encrypting the file. gpg --decrypt [FILE].gpg on the encrypted version of original file, upon which you\u0026rsquo;ll need to enter the original password. In this GPG implementation, encryption and decryption of your file both require knowledge of a single password, which in this case serves as the symmetric key.\nAsymmetric Cryptography # In asymmetric cryptography, two separate keys are respectively used for encryption and decryption. These two keys come in a public-private pair. The public key is made known publicly and used to encrypt data. Whereas, the private key is kept secret by the owner and used to decrypt data. Encryption of a file with a public key implies that only someone with the corresponding private key can the decrypt the resulting encrypted file.\nGPG Keyring Abstraction # GPG uses a \u0026ldquo;keyring\u0026rdquo; as a centralized location to hold all of a user\u0026rsquo;s keys. You\u0026rsquo;ll need to add/import a key to your keyring if you wish to use it and keep it around. Similarly, if you wish to share a key with someone else, you can export your key (which makes a copy of your key) and have them import it to their keyring.\nTo try it out:\ngpg --full-generate-key to generate a GPG public-private key pair. It\u0026rsquo;ll ask for a password. If your machine is taking a while to generate a key, it may be due to a lack of entropy (randomness) that is needed for a long, random key. sudo apt-get install haveged will install a daemon that generates entropy. gpg --recipient [RECIPIENT] --encrypt [FILE] which\u0026rsquo;ll encrypt [FILE] with [RECIPIENT]\u0026rsquo;s public key (for now, try encrypting a file with your own public key). gpg --decrypt [FILE].gpg will search through your keyring and decrypt the file with the appropriate private key (if you possess the correct private key, of course). You don\u0026rsquo;t need to specify which key to decrypt a file with because GPG-encrypted files and keys contain metadata that allow GPG to pick the correct key from the keyring to decrypt the file with. Signatures # The asymmetric scheme involving encryption with public key and decryption with private key can also be reversed to implement digital signatures whose role is equivalent to that of physical signatures. In this reversed scheme, the private key is used to sign a file, producing a signature on that file. And the corresponding public key is used to verify the signature. Therefore, only a person with the private key can produce a signature, but anyone with the corresponding public key can verify that signature.\nTo try it out: gpg --sign [FILE] to sign [FILE] with your private key. gpg --verify [FILE].gpg to verify that the file was signed by one of public keys on your keyring.\nHashing (Checksums) # Hash functions deterministically map arbitrary-length data to a fixed-length string of bits (AKA a hash). As a result, the latter can serve as a summary of the former if the former exceeds the latter in terms of byte length. For instance, if we download a 1GB file and want to verify its integrity, instead of re-downloading the entire file again, we can simply compute a 256-bit hash of the file on our end and compare it to the 256-bit hash of source, which is known as a checksum.\nTo try it out:\nsha1sum [FILE] to get the SHA1 hash of [FILE]. md5sum [FILE] to get the MD5 hash of [FILE]. There are many hash functions, only some of which satisfy the requirements of cryptographic hash functions. Crytographic hash functions primarily differ from their non-cryptographic counterparts in that they provide a property that make it computationally infeasible to forge a pre-hash file that maps to the same hash. If you are interested in all of the properties of a cryptographic hash function, read here. In particular, SHA1 and MD5 have been proven to no longer be cryptographically secure and are only used for checksums to ensure data integrity.\nFile Security # The UNIX permission model has 3 components: permissions given to the file\u0026rsquo;s (1) owning user, (2) owning group and (3) others/everyone else. Permissions themselves have 3 subcomponents: (1) read, (2) write and (3) execute, enforcing the ability to read, write or execute a file.\nTo try it out:\nls -l shows all the permissions of the current directory\u0026rsquo;s files in the leftmost column. chown [-R] [NEWUSER]:[NEWGROUP] [FILE] to change [FILE]\u0026rsquo;s user and group ownerships respectively to [NEWUSER] and [NEWGROUP]. chmod [-R] [PERMISSIONS] [FILE] to set [FILE] with specified [PERMISSIONS]. Lab Checkoff # Submission # Submit answers to each question on Gradescope.\nSetup # You should complete this lab on your student VM.\nOnce you\u0026rsquo;re connected to your VM, you\u0026rsquo;ll need download files for this lab:\nwget https://github.com/0xcf/decal-labs/raw/master/7/lab7.zip unzip lab7.zip -d lab7 cd lab7\nEncryption and Decryption # Decrypt file1.txt.gpg with the password ocfdecal (for real-life purposes, never store passwords in plaintext). What are the decrypted contents of file1.txt.gpg? What command allows you to import a key? What command allows you to export a key to a file? (Add the --armor flag to ASCII-encode the key so it can be sent easily in text form) What command allows you to see all of the keys on your keyring? Use the private key lab7privkey to decrypt the file file2.txt.gpg (for real-life purposes, it is necessary to keep private keys secret). What are the decrypted contents of b8/file2.txt.gpg? Hashing (Checksums) # What is the MD5 hash of file3.txt? What is the SHA1 hash of the MD5 hash of file3.txt? In other words, what is SHA1(MD5(file3.txt))? File Security # Run sudo setup.sh before beginning this section.\nfile4.txt: What are the permissions of this file? Explain what they allow and disallow. file5: Make this file executable and execute it. What is its printout? file6.txt: Change this file to be under your ownership. What command did you use? file7.txt: Make this file readable only to you. What command did you use? file8.txt: Change this file\u0026rsquo;s permissions such that only root should be able to read this file and no one should be able to edit it. What command did you use? file9.txt: Choose any method to make this file readable to you and unreadable to the previous owner. What command did you use? "},{"id":16,"href":"/announcements/week-7/","title":"Week 7","section":"Announcements","content":"Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu!\nHi everyone, we\u0026rsquo;re entering week 7 of the DeCal! At this point, you should have turned in your Lab 6 on Gradescope. Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 03/18 7-9PM PST. Experimental track on Thursday same time!\nSlides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm.\nLab 7 has been released and can be accessed below.\nPlease use the corresponding Ed thread for Lab 7 related questions.\nAny questions? Post on Ed or reach us at decal@ocf.berkeley.edu!\n"},{"id":17,"href":"/announcements/week-8/","title":"Week 8","section":"Announcements","content":"Happy spring break everyone, we\u0026rsquo;re entering week 8 of the DeCal! At this point, you should have turned in your Lab 7 on Gradescope. Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 04/01 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 8 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 8 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":18,"href":"/labs/8/","title":"Lab 8 - Version Control and Backups","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} In this lab, we\u0026rsquo;ll be learning how to use Git and typical best practices for version control!\nPulling the code # If you haven\u0026rsquo;t already cloned the decal-lab git repository, run:\n$ git clone https://github.com/ocf/decal-labs.git Go to your decal-labs directory and cd into the folder b9. Run git pull to pull the latest changes.\nPart 1: Git Basics # In the b9 directory, we\u0026rsquo;ve provided a basic Python program called rand.py to help demonstrate some core Git concepts. rand.py takes command line arguments and performs a number of coin flips and outputs the result in your terminal. We want to add a feature to rand.py that also lets us perform dice rolls. We will simulate the real-world development process by making a branch for our new dice rolling feature, making a few commits to that branch, and then merging our feature branch into the master branch. You won\u0026rsquo;t need to personally write any Python for this lab! You will only need to copy-and-paste the code we provide, since this lab is about learning version control and not Python.\nrand.py demo # Run python3 rand.py -h in your terminal to see the help dialogue for the program. At the moment, it takes one positional argument of either coin or dice as well as an optional flag -i (or --iterations) if you want to flip/roll more than once. The dice argument doesn\u0026rsquo;t work as we haven\u0026rsquo;t implemented it yet, but you can try flipping a coin:\n~/decal-labs/b9$ python3 rand.py coin 1 coin flip(s) resulted in 0 Heads and 1 Tails: T ~/decal-labs/b9$ python3 rand.py coin -i 10 10 coin flip(s) resulted in 3 Heads and 7 Tails: T, T, H, T, H, H, T, T, T, T ~/decal-labs/b9$ python3 rand.py coin -i 999 Number of flips must be in the range [0 - 100] Creating a new branch # Let\u0026rsquo;s start working on the dice rolling feature! When working on a project with version control, it\u0026rsquo;s best practice to keep the master branch clean (read: mostly bug-free and stable).\nAny branches you make will be based on/descended from code in the master branch. You don\u0026rsquo;t want to write new code on top of a foundation that\u0026rsquo;s broken or buggy!\nSome organizations may directly deploy the master branch to a production environment (live for your users and clients), so new and work-in-progress features should be developed in their respective branches and finished before merging them into master.\nLet\u0026rsquo;s make a branch for our dice rolling feature:\n$ git checkout -b dice This makes a new local branch called dice based on the branch that we are currently on (master) and switches you to the dice branch. This command is basically shorthand for:\n$ git branch dice # Create new branch called \u0026#39;dice\u0026#39; $ git checkout dice # Switch to branch called \u0026#39;dice\u0026#39; You can view the branches you\u0026rsquo;ve created by typing git branch. You should see two branches at this point, one called master and one called dice. An asterisk is placed next to the branch that you\u0026rsquo;ve currently checked out.\nYou can make git branch (and many other command-line tools) display more information by passing the verbose flag -v, or make it display even more information by adding additional v characters to the flag (e.g. -vv). For example, git branch -v will display the commit message of the most recent commit on the branch (aka the HEAD). git branch -vv also displays in square brackets the remote branch that the local branch is tracking, if one exists. In this repository, master is associated with a remote branch origin/master that lives on Github\u0026rsquo;s servers. This means when you git push or pull to/from origin master, you are syncing up your local copy of the master branch with the remote master branch on Github\u0026rsquo;s servers. At the moment, your newly created dice branch is local only, meaning that it is not tracked. Therefore attempting to git push or git pull will not work (or Git may ask if you want to have a remote branch created).\nMaking commits # Now that you\u0026rsquo;ve created and swapped to the dice branch, you can safely start adding code without modifying the master branch. The code for dice rolling will be split up into three commits so that we can demonstrate how to combine multiple commits into a single commit later. Open rand.py in your preferred text editor. Find the comment in the __main__ function that says COMMIT 1 and add the following code below it like so:\n# COMMIT 1: Add -s flag for number of sides on a die parser.add_argument( \u0026#34;-s\u0026#34;, \u0026#34;--sides\u0026#34;, dest=\u0026#34;sides\u0026#34;, type=int, default=6, help=\u0026#34;Number of sides on a die (max=20; ignored when flipping a coin)\u0026#34; ) If you\u0026rsquo;re unsure about copying the code correctly, take a look at rand_reference.py for what the finished code should look like!\nSave and exit the text editor and return to the terminal. Type git status to see that rand.py has been changed but not staged. Type git add rand.py to stage the file. To \u0026ldquo;stage\u0026rdquo; a file means to add it to the group of files that you want to include in your commit.\nYou may already know git add . to add every changed file in your current directory to the staging area, but in some cases you want to only add relevant files if you hopped around implementing different things. A commit should be a group of changes focused on a single small goal, sub-feature, or bug fix. In the event that you need to roll back a commit, you don\u0026rsquo;t want to cause collateral damage by undoing changes in an unrelated file that you lumped into the commit.\nNow, lets commit our changes and write a concise and useful commit message. Type git commit -m \u0026quot;Add -s flag for number of sides on a die\u0026quot;. Organizations and companies will have different best practices for writing commit messages, but here are some common guidelines:\nKeep it short. Typical commits should be one line (some exceptions). If a lot of changes have been made, you might want to make multiple commits instead.\nMake it descriptive. If someone needs to read the commit history, they\u0026rsquo;re not going to know or remember what was changed by a commit that just says \u0026ldquo;Fixed bug\u0026rdquo; or \u0026ldquo;WIP\u0026rdquo;.\nA lot of places like to capitalize the first letter and use the \u0026ldquo;\u0026lt;present tense verb\u0026gt; \u0026lt;descriptive thing\u0026gt;\u0026rdquo; sentence structure. For example, \u0026ldquo;Add\u0026rdquo;, \u0026ldquo;Fix\u0026rdquo;, or \u0026ldquo;Remove\u0026rdquo; some thing. You can think of your commit message as completing the sentence \u0026ldquo;This commit will\u0026hellip;\u0026rdquo;. For example, \u0026ldquo;This commit will add -s flag for number of sides on a die\u0026rdquo;.\nNext, we will follow the same procedure to make commits 2 and 3.\nFind the comment in the function roll_dice that says COMMIT 2 and add the following code. Make sure that it\u0026rsquo;s indented properly inside the function! Then stage your changes and make a commit with the message \u0026quot;Add dice rolling logic and output dice sum and sequence\u0026quot;.\n# COMMIT 2: Add dice rolling logic and output dice sum and sequence diceRecord, diceSum = [], 0 for i in range(iterations): roll = random.randint(1, sides) diceRecord.append(roll) diceSum += roll print(\u0026#34;{} roll(s) of a {}-sided die resulted in a sum of {}:\u0026#34; .format(iterations, sides, diceSum)) print(*diceRecord, sep=\u0026#39;, \u0026#39;) Find the comment in the function roll_dice that says COMMIT 3 and add the following code. Then stage your changes and make a commit with the message \u0026quot;Restrict input range for dice iterations and sides\u0026quot;.\n# COMMIT 3: Restrict input range for dice iterations and sides if iterations \u0026gt; MAX_ITERATIONS or iterations \u0026lt; 0: print(\u0026#34;Number of rolls must be in the range [0 - {}]\u0026#34; .format(MAX_ITERATIONS)) return if sides \u0026gt; MAX_SIDES or sides \u0026lt; 1: print(\u0026#34;Number of sides must be in the range [1 - {}]\u0026#34; .format(MAX_SIDES)) return When you\u0026rsquo;re done, you should now be able to roll dice:\n~/decal-labs/b9$ python3 rand.py dice -i 10 -s 20 10 roll(s) of a 20-sided die resulted in a sum of 119: 15, 3, 12, 10, 16, 8, 18, 20, 13, 4 Viewing your progress # Let\u0026rsquo;s take a look at the commits you\u0026rsquo;ve made. Type git log to see a history of commits. Each commit has some information such as who authored the commit, a timestamp for when the commit was created, and the commit message.\nThe first line of each commit entry has a long hexadecimal string. This is the commit hash: think of it as a unique ID that you can use to reference that specific commit.\nSome commits have branch information in parentheses next to the commit hash, indicating that they are the most recent commit or HEAD of that branch. Your most recent commit should have something like (HEAD -\u0026gt; dice). The fourth commit should have (origin/master, origin/HEAD) because we based our branch off of master and have added three new commits on top of it. Note that if someone adds new commits to the local or remote master, the branch information may change or be out of date.\nType q to exit git log.\nBesides looking at the commit history, you may want to view the actual changes in the code. You can use git diff \u0026lt;old commit\u0026gt; \u0026lt;new commit\u0026gt; to view the difference between two commits. There are a few different ways you can reference a commit. One that was mentioned before was copying a commit\u0026rsquo;s hash (note that your commit hashes will be different from the example below):\n$ git diff 3368313c0afb6e306133d604ca72b0287124e8f2 762053064506810dee895219e5b2c2747a202829 You can also copy a small chunk of the beginning of the commit hash instead of the entire hash. Because of the way hashes work, it\u0026rsquo;s very unlikely that you\u0026rsquo;ll have two commits that have the exact same starting sequence.\n$ git diff 3368313 7620530 If you\u0026rsquo;re trying to diff two commits that are pretty close together in the log, an easier way is to reference commits by their distance from the HEAD (most recent) commit using the format HEAD~\u0026lt;number\u0026gt;. Since we added three commits new commits in dice, we can view the difference between dice and master using the following command:\n$ git diff HEAD~3 HEAD Merge conflicts and rebase # Now that you\u0026rsquo;ve implemented dice rolling on on your feature branch, you\u0026rsquo;ll want to merge your feature into the master branch. This means that Git will take your changes on the dice branch and and replay them on the master branch, bringing master up to date with dice. However, things can ( and often will) go wrong when master has new commits added to it while you\u0026rsquo;re working on dice. Now, our commits on dice may be based on an old version of master. Even worse, someone else may have modified the same lines of code on master that we changed on dice, resulting in Git not knowing whose lines to use. This is called a merge conflict.\nLet\u0026rsquo;s simulate a merge conflict by making a change on master. Switch to the master branch using git checkout master. Make sure that you\u0026rsquo;re on the master branch by checking the output of git branch. Now that you\u0026rsquo;re on the master branch, rand.py shouldn\u0026rsquo;t contain the code for the new dice feature we added. Go to the comment that says COMMIT 2 and add the following code below:\n# COMMIT 2: Add dice rolling logic and output dice sum and sequence diceSum = random.randint(1, iterations * 6) print(\u0026#34;{} roll(s) of a {}-sided die resulted in a sum of {}:\u0026#34; .format(iterations, sides, diceSum)) Now stage the changes and commit with the message \u0026quot;dice rolling WIP\u0026quot;. In this totally realistic scenario, our imaginary maverick teammate has added some buggy code to master, making your life harder. Switch back to your dice branch with git checkout dice and prepare to handle this merge conflict.\nThere are a multiple ways to handle a merge conflict, but the one we will be showing you in this lab is using git rebase. Our dice branch is \u0026ldquo;based\u0026rdquo; on the master branch at a certain point in time, but the master branch has moved forward leaving dice based on an outdated master. Thus, we want to \u0026ldquo;re-base\u0026rdquo; dice on the current state of master. While on your dice branch, run git rebase master. Git will rewind the commits you\u0026rsquo;ve made on dice, copy any new commits made on master, and attempt to replay your commits on top. Sometimes rebase will run to completion without your intervention, but if there\u0026rsquo;s a merge conflict you will need to resolve it.\nGit will give you instructions on what to do if it encounters a merge conflict during a rebase. In this case, open rand.py and find the conflicted zone which should have the following format:\n\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Lines of code from the base branch (in this case master) ======= Lines of code from the branch you\u0026#39;re rebasing (in this case dice) \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; Commit message of the commit that conflicts with the base branch To fix the conflict, simply keep the lines you want (your lines from dice) and delete the other lines in the conflicted zone (\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; dice, and the unwanted code from master), and then save and exit the file. Git will take what you\u0026rsquo;ve saved as the exact form of what the file will look like at the end of the rebase, so what you\u0026rsquo;re doing is essentially fixing the file so that the code runs properly. This means that if you have multiple merge conflicts and you decide to mix keeping some lines from the base branch and some from your feature branch, you need to make sure the code actually works correctly.\nNow that you\u0026rsquo;ve fixed the merge conflict, follow the rebase instructions and stage your fixed file (git add rand.py), then run git rebase --continue. If Git finds any more merge conflicts for other files, you would follow the same procedure as above. However, we only had one conflicted file so our rebase is finished! Run git log to see the result of our rebase. You should now see that your imaginary teammate\u0026rsquo;s \u0026quot;dice rolling WIP\u0026quot; commit in your branch\u0026rsquo;s history, with your commits on top of theirs.\nWait! We haven\u0026rsquo;t actually merged our commits into the master branch. If you want to do the optional step of combining your commits into a single commit before merging, go to the next section. You can also merge now and do the optional step later; you won\u0026rsquo;t see the combined commit on master but you will still learn the concepts. Otherwise, switch to the master branch using git checkout master and run git merge dice to integrate your changes from dice into master. Now you\u0026rsquo;re done! Don\u0026rsquo;t forget to complete the quick Gradescope check below.\nBecause we ran rebased our branch before merging, we didn\u0026rsquo;t get any merge conflicts when running git merge dice. You can simply git merge dice without rebasing first, but Git will prompt you to resolve the exact same merge conflicts before it allows a merge so you aren\u0026rsquo;t saving yourself any work. We decided to show git rebase because it\u0026rsquo;s a good habit to regularly sync your branch with its base branch. Run git rebase every so often if you suspect there are new changes on master so that any merge conflicts are small and incremental. If you work with a large team and toil away on your feature branch for several days without rebasing, you may find that when its time to merge, your teammates have already updated master many times giving you a large backlog of merge conflicts and an even larger headache.\nGradescope:\nOn your master branch, type git log and paste a portion of your commit history showing the commit(s) you merged in from your dice branch plus a few commits into the past for context. If you haven\u0026rsquo;t completed the optional \u0026ldquo;Combining commits\u0026rdquo; section, 5-6 of the most recent commits should be sufficient. If you have completed the optional section and squashed your commits, 3-4 of the most recent commits should be sufficient.\nOn the master branch, use git diff to show the difference between what rand.py looks like now versus what it looked like at the start of the lab. There are multiple ways to use git diff to do this, so pick any one you like. In Gradescope, paste both the git diff command you used and the output of the command.\n(OPTIONAL) Combining commits # Git has the ability to combine multiple commits into a single commit. This process is called squashing. You may want to do this if you have work in progress commits that you want to combine into a single finished commit, or in our case, keeping git log for the master branch more digestible.\nPros: If you have a feature branch with fifty commits, you prevent inundating master\u0026rsquo;s history with fifty different commits when merging. When you squash, you can make a multi-line commit message where the first line is a summary of the feature, and subsequent lines are bullet points containing relevant individual commit messages from the individual commits.\nCons: You lose the granularity of the history on master, making it more difficult if you want to partially roll back your feature. Git also doesn\u0026rsquo;t support having multiple authors for a single commit, so if you want to credit other contributors you need to add co-author credit somewhere in the commit message of your combined commit. Aside: you can see how co-authoring works with GitHub here.\nFirst, make sure you\u0026rsquo;re on your dice branch using git checkout dice. We will be performing our squash using the command git rebase in interactive mode by passing the -i flag. This may seem a bit unusual that we can run rebase without a base branch, but rebase can not only sync branches, but also rewrite the history of our current branch.\nThe format for the command of an interactive rebase is git rebase -i HEAD~# where # is the parent commit of the commit where we want to start our rebase. This will seem a bit unintuitive if you\u0026rsquo;ve followed how the HEAD~# pointer works: to work on our last three commits (HEAD, HEAD~1, and HEAD~2), we need to actually run git rebase -i HEAD~3. An easier way to remember this is if you want to rebase the last N commits, run git rebase -i HEAD~N. However, we may not always remember how many commits we made so its okay to give yourself a little more room/context by using a larger number.\nLet\u0026rsquo;s run git rebase -i HEAD~5. This will bring up a text editor with a file that we can modify to change the history of commits from HEAD~4 to HEAD. You\u0026rsquo;ll notice that the commits are in reverse order, starting with the oldest commit at the top and newest commit at the bottom. This is because git will use this text file as part of a script to replay those commits (with your rewritten changes) in chronological order. Your file will have different commit hashes and likely a different commit message on the first line than the example below:\npick 7c5bd5d fixed sus pick 1f7a1e1 dice rolling WIP pick 26e0827 Add -s flag for number of sides on a die pick b193d44 Add dice rolling logic and output dice sum and sequence pick 554402e Restrict input range for dice iterations and sides # Rebase 7dac858..554402e onto b193d44 (5 commands) # ... As you can see, Git includes useful instructions on what you can do with commits in interactive mode in the commented-out section at the bottom of the file. We can combine, delete, reword, or even reorder our commits, along with many more options. In our case, we want to squash our two most recent commits into the third most recent commit in the list. To do this, replace the word pick with the word squash (or just s for short) on the last two lines. Do not squash the third line; that will take your three most recent commits and meld them with the \u0026ldquo;dice rolling WIP\u0026rdquo; commit, which is a commit from master. Your file should look something like this:\npick 7c5bd5d fixed sus pick 1f7a1e1 dice rolling WIP pick 26e0827 Add -s flag for number of sides on a die squash b193d44 Add dice rolling logic and output dice sum and sequence squash 554402e Restrict input range for dice iterations and sides # Rebase 7dac858..554402e onto b193d44 (5 commands) # ... Save and exit the file. Git will now rewrite the commit history as you specified. If you squash commits or do another action that may modify commit messages, Git will bring up another text editor for you to modify the commit message. Because you squashed, Git made a multi-line commit message by combining the three individual commit messages from before you squashed. Let\u0026rsquo;s add a useful one-line summary, \u0026ldquo;Add dice roll feature\u0026rdquo;, at the top of the file. You can also adjust the formatting to your liking; I like adding bullet points to the individual commit messages.\nAdd dice roll feature # This is a combination of 3 commits. # This is the 1st commit message: - Add -s flag for number of sides on a die # This is the commit message #2: - Add dice rolling logic and output dice sum and sequence # This is the commit message #3: - Restrict input range for dice iterations and sides Git and other tools use the first line of a commit message as a shortened version for certain display purposes. For example, try running git log --oneline. As another example, when Github displays the most recent commit message next to files and folders in the directory view, the first line of the message is shown.\nSave the file and exit. The rebase is now complete! Type git log and view your new squashed commit. If you didn\u0026rsquo;t already merge your three individual commits into master, you can run git merge master to merge in your combined commit.\ncommit 6b4f705921f9b06af880f97d36cb0b74e51aeb0c (HEAD -\u0026gt; dice) Author: Max Vogel \u0026lt;max-v@berkeley.edu\u0026gt; Date: Sun Apr 3 19:45:51 2022 -0700 Add dice roll feature - Add -s flag for number of sides on a die - Add dice rolling logic and output dice sum and sequence - Restrict input range for dice iterations and sides Gradescope: There\u0026rsquo;s no separate Gradescope check for this optional section, but make sure you go back and complete the Gradescope check above in the previous section if you\u0026rsquo;ve chosen to do this part first!\nPart 2: Pull Requests # One of the most common ways to contribute changes to a repository on Github (and other similar Git remote hosting services) is through a pull request (often shortened to \u0026ldquo;PR\u0026rdquo;). A pull request is basically a proposal to make changes to a repository that can be reviewed by others, commented on, and edited before the changes are actually approved to be merged into the repository. For example, when working on a large project with a team, you may want to submit a pull request with your new feature so that team members can review your code for bugs or code style mistakes. For projects on public repositories that invite contributions from strangers, you can contribute a feature by forking the repository (making a copy of it that you own), implementing your feature, and then making a pull request to have your contribution merged into the official repository.\nFirst, read up on how to create a pull request from Github\u0026rsquo;s documentation. We\u0026rsquo;ve created a dummy repository at github.com/ocf/decal-pr-practice for you to practice making a simple PR from a fork. You will be making a fork of the repo, writing your name in the Markdown file in the repo, and then making a PR to merge your change into the original repo.\nRead about how to fork a repo from Github\u0026rsquo;s documentation. Make a fork of our dummy repository at github.com/ocf/decal-pr-practice.\nClone your forked repository and create a new branch based on master called my-name. Open README.md and replace \u0026ldquo;Tux the Penguin\u0026rdquo; with your name.\nStage and commit your change with the commit message Add my name, and then git push.\nRead about how to make a PR from a fork from Github\u0026rsquo;s documentation. Make a PR from your branch my-name on your forked repo \u0026lt;Your Github username\u0026gt;/decal-pr-practice to the branch master on the original repo ocf/decal-pr-practice.\nYou\u0026rsquo;ve now made a pull request! Github has a lot of features for pull requests, feel free to check some of them out.\nThe main page for the pull request has a timeline of commits and any comments from reviewers. PRs can be continually updated by making and pushing new commits to your compare branch. Github will track any new changes pushed to the compare branch and update your PR. As you can see, I didn\u0026rsquo;t follow my own advice and messed up a rebase after trying to sync my fork, leaving duplicate commits in my commit history\u0026hellip;\nThe sidebar on the main page has several notable features. You can request other people to review your changes, assign others to work on the PR, and link an issue that your PR will resolve if it gets merged. Github repositories have an \u0026ldquo;Issues\u0026rdquo; tab where one can submit a report about a bug or request a feature (e.g. github.com/ocf/decal-web/issues).\nGo to the \u0026ldquo;Files Changed\u0026rdquo; tab to see a diff of the PR\u0026rsquo;s changes. Reviewers of your PR can leave inline comments on a specific line of code by hovering over the line and clicking the blue \u0026ldquo;+\u0026rdquo; button that pops up.\nGradescope: Paste a link to the pull request you made so that it can be checked off for completion.\nPart 3: Questions # What caused the merge conflict in the Git exercises you did?\nWhy does Git require us to manually intervene in merge conflicts?\nIn our exercise of making pull requests, why did we fork the repository before making a PR?\nWhat command would you use to sync a folder ~/Downloads/Linux_ISOs to the folder /usr/local/share/Calendar, while preserving file metadata? (hint: use rsync)\nHow does rsync determine when to look for changes between files? Select from the following: (read up on how rsync works, and what makes it efficient!)\nA. By calculating the checksum of each file and comparing them.\nB. By comparing the entire contents of each file for any differences.\nC. By seeing if the \u0026rsquo;last modified\u0026rsquo; timestamp of the files are different.\nD. By seeing if the \u0026lsquo;created\u0026rsquo; timestamp of the files are different.\nE. By seeing if the permissions of the files are different.\n"},{"id":19,"href":"/labs/9/","title":"Lab 9 - Containers (Docker)","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Overview # This lab is designed to give you some hands-on experience with Docker! By the end of this assignment, you should be able to:\nCreate and use a Docker container interactively and create a Dockerfile, which allows you to declaratively define your containers. Keep track of your answers to the questions, as you\u0026rsquo;ll need to submit them to Gradescope.\nGetting started with Docker # You have a couple of options for installing Docker. It is recommended to follow the \u0026ldquo;Install using the apt repository\u0026rdquo; section.\nAfter installing, run sudo usermod -aG docker $USER, then logout and login again. This adds your user to the docker group so you can run docker as a non-root user. This means you won’t have to type sudo docker all the time. This is optional but for the rest of the lab I’m going to assume that you did this.\nCreating your first Docker container # To verify that you installed things correctly, try running:\ndocker run hello-world\nYou should see some friendly output like so:\nUnable to find image \u0026#39;hello-world:latest\u0026#39; locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:c3b4ada4687bbaa170745b3e4dd8ac3f194ca95b2d0518b417fb47e5879d9b5f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. ... This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps:\nThe Docker client contacted the Docker daemon. The Docker daemon pulled the “hello-world” image from the Docker Hub. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. Some quick definitions from Docker’s website:\nAn image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. Images are useful primarily for their speed, but images can also be used as a base to be built on top of in future images, as you’ll see later with Dockerfiles. In the last example hello-world was the image used to test our docker installation.\nA container is a runtime instance of an image—what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so. A container gets created upon executing docker run on an image.\nBe sure to read through the output from running the hello-world image to get an understanding of what the Docker daemon was doing.\nRunning an interactive container # Now, let\u0026rsquo;s try to run a container interactively. This is useful if you ever need to play around and install stuff on a bare system without messing up your current system. Try running the following command:\ndocker run -it ubuntu:latest\nThe -i flag tells docker to keep STDIN open to your container, and the -t flag allocates a pseudo TTY for you. Basically you need both for you to have a shell into your newly started container. Try installing some packages from apt or just play around. It should look like a bare Linux system.\nYou can exit the container with CTRL+D.\nQuestions # What user are you logged in as by default in the container? If you start and then exit an interactive container, and then use the docker run -it ubuntu:latest command again; is it the same container? How can you tell? Dockerfiles # The natural question is, how are Docker images built? A Dockerfile is like the source code of an image. Rather, a Dockerfile allows you to define an image by specifying all of the commands you would type manually to create an image. Docker can then build images from a specified Dockerfile. These Dockerfiles can be put into version control and the images uploaded to online repositories. Can you see how this can be useful for deploying your application?\nDockerfiles are very powerful and have many different commands and features. We’ll go over a basic example, but you should check out the reference page if you are trying to do anything more complex.\nLet\u0026rsquo;s jump in. We\u0026rsquo;re going to create an image that deploys your new startup\u0026rsquo;s app, Missile! Unfortunately, so far you only have the opening animation complete, and the source code is in b10/missile.py in repo - decal-labs.\nYour program has a couple of dependencies. Namely, it requires Python and the python packages termcolor and pyfiglet to be installed. Here is a Dockerfile that puts those requirements into code, by installing Python 3 and the packages onto a base Fedora Linux image.\n# Specify Fedora Linux as base image FROM fedora:latest # Install Python with yum (Fedora\u0026#39;s Package Manager) # Install required Python packages RUN yum update -y \u0026amp;\u0026amp; yum install -y python3 python3-pip \u0026amp;\u0026amp; \\ python3 -m pip install pyfiglet termcolor # Add the missile.py file to the final image ADD missile.py / # Specify the command to be run on container creation CMD [\u0026#34;/usr/bin/python3\u0026#34;, \u0026#34;missile.py\u0026#34;] Note: there are some “best practices” for writing Dockerfiles that the above example doesn’t use, because it’s a basic example. If you’re interested in this stuff, check out this article.\nTake a moment to appreciate how cool this is. We have a completely different Linux distribution with an application running on our system that can all be spun up with a single command. Now, when (if?) your startup finally takes off, scaling up will be a breeze!\nMake sure you have both files named missile.py and Dockerfile respectively then build the image with the following command:\ndocker build -t missile:latest .\nThis tells Docker to look in the current directory for a Dockerfile to build, and builds it. The -t flag tells Docker to tag this build with the name missile:latest. Note that building the missile image will take a couple of minutes to complete.\nYou can see all of the images you’ve built on your machine with the docker images command.\nQuestions # Run the image you just built with no flags. What do you observe? Write and build a Dockerfile based on ubuntu:bionic that installs the packages fortune and fortunes-min and runs the fortune executable (located in /usr/games/fortune after you install it). Note that you won’t need to use the -it flags when you run the container as fortune doesn’t need STDIN. Submit your Dockerfile with this lab. Hint: if you’re having trouble writing your Dockerfile, try booting an interactive container and installing both packages. How can you translate what you did interactively to a Dockerfile? Paste the output of running docker images command after completing questions 1 and 2. Dockerizing a Web Server # For our last trick, we’re going to use Docker to run multiple Apache web servers inside containers.\nFor simplicity, you will not have to write this Dockerfile. Go ahead and pull the httpd image from Docker Hub. Now, it’s your job to figure out how to run three instances of the Apache containers on your machine.\nDocker creates a separate network for containers, so you will need to forward your host port to your container’s port (this is called port forwarding, or port mapping). The container is listening on port 80 by default. It is your job to run each instance on ports 4000, 4001, and 4002. I recommend running the containers in detached mode with the -d flag. Detached mode will run a container in the background and print its new container ID. You can view running containers with docker ps.\nHints:\nThe -p flag takes in a colon separated pair of HOST_PORT:CONTAINER_PORT (it can actually accept a ton of more options, but don’t worry about that for now). You can see if you were successful by executing curl localhost:4000 on your student VM. Check that you;\u0026rsquo;ve also done it correctly for ports 4001 and 4002. Refer to the Docker commands slide if you\u0026rsquo;re stuck! Questions # While your three containerized Apache web servers are running in detached mode, paste the output of docker ps. Observe that in the output of docker ps, each container has an associated container ID. Explain why containers have IDs/Names rather than being named after the image, for example httpd. Now go ahead and stop your containers. Paste the command you used to stop one of the containers. Congratulations! You’ve successfully Dockerized and ran a web server without affecting your setup on your machine :) There’s a lot more about Docker and containers to learn about, but I hope this was enough to wrap your head around the basic concepts and get some experience working with it.\nFor further reading - official documentation\n"},{"id":20,"href":"/announcements/week-9/","title":"Week 9","section":"Announcements","content":"Hi everyone, we\u0026rsquo;re entering week 9 of the DeCal! At this point, you should have turned in your Lab 8 on Gradescope. Most lab should also be graded by now. Weekly notes:\nNormal schedule, Lecture + Lab on Tuesday 04/08 7-9PM PST. Experimental track on Thursday same time! Slides link are released, but are not official/finalized until after lecture is given on Tuesday 7pm. Lab 9 has been released and can be accessed below. Please use the corresponding Ed thread for Lab 5 related questions. Any questions? Post on Ed or reach us at decal@ocf.berkeley.edu! "},{"id":21,"href":"/labs/10/","title":"Lab 10 - Puppet","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Overview # For this lab, we will be installing and configuring a Minecraft server. All of this configuration can be successfully done without a Minecraft client or knowledge on how to play the game itself.\nIf you want to actually be able to connect to the server: If you\u0026rsquo;re not using the provided VM make sure your Linux VM has enough RAM to host the server (2-4Gb).\nGetting help # If you want any help with any part of this lab, join the OCF Discord ( https://ocf.io/discord) and ask in the #decal-general channel!\nThe original creator of this lab is Frank Dai (fydai), and there was originally a message here telling you to ping him if you needed any help. You are still welcome to try (or, you can also ping current decal facilitators as well) :)\nThe most important trick with puppet # If you mess anything up, delete everything (in particular /home/minecraft), and just run puppet again! Puppet ensures that even starting from nothing, you can reconstruct your entire previous state. If you do this and get issues with Puppet executing things out of order than you would like them, add in a require parameter to the resource that should be defined later. For instance, if you want to create something after the /home/minecraft directory, throw in an require =\u0026gt; File['/home/minecraft'] option. In general, capitalize the name of the resource, and put the string before the colon between the square braces.\nPart 1: Installing Puppet # First, we’re going to install Puppet.\nsudo apt install puppet If you installed puppet with an earlier version of the lab and it isn\u0026rsquo;t working, please use the command below and then install puppet with apt.\nsudo dpkg -i --force-overwrite /var/cache/apt/archives/puppet_5.5.22-4ubuntu0.2_all.deb Part 2: Using Puppet # Make a minecraft.pp file anywhere, which through the course of this lab, will eventually configure and run a Minecraft Server. To run your puppet code, use sudo puppet apply minecraft.pp. Puppet, being declarative, will do nothing if the system is already configured properly, so run puppet early and often to detect bugs as soon as possible.\nUseful references are this section are the Puppet documentation and there is a lot of sample code avaliable in the OCF Puppet configuration. When you are stuck, looking at existing code and see how they did things will generally be helpful. Also remember that there are code examples on the slides!\nPart a: Making a Home Directory and a User # Put the following code into minecraft.pp:\nfile { \u0026#39;/home/minecraft\u0026#39;: ensure =\u0026gt; \u0026#39;directory\u0026#39;, } Run sudo puppet apply minecraft.pp to apply it, and ensure that the /home/minecraft directory was created.\nInside minecraft.pp, write some Puppet code to create a user named minecraft, that the Minecraft server will run under. The minecraft user should have home directory /home/minecraft. Now modify the code creating /home/minecraft to set owner the owner to minecraft user you just made. Check the example code on the slides if you are unsure about how to do this.\nChecking Part a # Run sudo puppet apply minecraft.pp.\nNow run ls -l /home and verify that /home/minecraft is owned by the minecraft user.\nPart b: Install java # Add a few lines to minecraft.pp to install the default-jre package.\nChecking Part 2b # Run java and verify that the binary exists.\nPart c: Installing the Minecraft Server configuration # Copy paste the contents of https://raw.githubusercontent.com/0xcf/decal-labs/master/a10/server.properties locally into a file named server.properties\nEnsure that /home/minecraft/server.properties contains the contents of the server.properties you just saved.\nHint: Use the file function! Also note that in this lab, you should be using absolute file paths.\nRead and agree to the Minecraft EULA, and ensure that /home/minecraft/eula.txt contains the text eula=true by hardcoding the string eula=true into your minecraft.pp.\nMake sure that all of the above files are owned by the minecraft user.\nChecking Part c # Run ls -l /home/minecraft and ensure that the above files exist, contain what they\u0026rsquo;re supposed to, and they are all owned by the minecraft user, not yours.\nPart d: Installing the Minecraft Server # Ensure that /home/minecraft/server.jar contains the Minecraft Server, available at https://piston-data.mojang.com/v1/objects/1b557e7b033b583cd9f66746b7a9ab1ec1673ced/server.jar. This server jar is for Minecraft 1.16.5, if you\u0026rsquo;d like to run a different version you can download the jar from within the Minecraft launcher or from the Minecraft wiki.\nNote that the source parameter of the file resource accepts a URL as its argument. Also make it owned by the minecraft user.\nChecking Part d # You know what to do!\nPart e: Templating a systemd unit file # Copy the following template into the same directory into your minecraft.pp file as minecraft.service.erb.\nEdit the file to be a proper erb template, so that \u0026lt;INSERT YOUR RAM AMOUNT HERE\u0026gt; becomes the value of the memory_available variable when puppet runs. You want to use the templated variable @memory_available in the .erb file, and declare the variable $memory_available it in the .pp file.\nHint: In the slides), there is an example of templating a file.\nHint 2: A .erb (Embedded Ruby) file means that Ruby is used as the templating language instead of the puppet language. Make sure not to confuse the syntax between the two!\nNow edit your minecraft.pp file, so that it sets the $memory_available variable to be the half the total amount of RAM available to the system (use Google and StackOverflow), and that it puts the templated file into /etc/systemd/system/minecraft.service.\nHint: You need to figure out how to define variables and set variables in puppet. Note that variables should be prefixed by $. You can assign variables just like any other language. Don\u0026rsquo;t forget to look at the sample code on the slides (it doesn\u0026rsquo;t cover variable assignment however) and don\u0026rsquo;t forget to use absolute paths!\nNote that the systemd unit file does not have a proper ExecStop, which maybe result in some world corruption.\n[Unit] Description=Minecraft Server Wants=network.target After=network.target [Service] User=minecraft WorkingDirectory=/home/minecraft # This should look like ExecStart=/usr/bin/java -Xmx504578 -jar server.jar ExecStart=/usr/bin/java -Xmx\u0026lt;INSERT YOUR RAM AMOUNT HERE\u0026gt; -jar server.jar ExecStop=/bin/kill -- $MAINPID TimeoutStopSec=5 [Install] WantedBy=multi-user.target Checking Part e # Look at /etc/systemd/system/minecraft.service to ensure it contains the contents you want before proceeding.\nPart f: Running the service # Ensure that the minecraft systemd service is enabled and started.\nChecking Part f # This is the critical moment! If you\u0026rsquo;ve done everything before correctly, this should work (until Minecraft OOMs)! If the systemd unit fails immediately, try to run the ExecStart command manually, by going into /home/minecraft/ and running sudo -u minecraft java -Xmx1009156 -jar server.jar.\nYou can verify that something is trying to start by running tail -f /home/minecraft/logs/latest.log. If it ever stops loading, the server has run out of memory, and \u0026ldquo;Part h\u0026rdquo; below should have a workaround.\nPart g: Backups # We should backup our minecraft server!\nEnsure there is a directory /home/minecraft/backups/, owned by the minecraft user.\nEnsure there is a script, /home/minecraft/backup.sh that is executable, with the following contents however you\u0026rsquo;d like.\n#!/bin/sh cp -r /home/minecraft/world \u0026#34;/home/minecraft/backups/world-$(date -Is)\u0026#34; The command copies the directory containing into the minecraft world into a subdirectory of backups indexed by the current date.\nUse puppet to add a cron entry to execute /home/minecraft/backup.sh every minute as the minecraft user.\nChecking Part g # Look in the /home/minecraft/backups contains backups!\nPart h: (Bonus, optional if you want Minecraft to not Out Of Memory) # We could be doing this by typing this a bunch of commands to add a swap file, and enabling it as swap, but we will do this puppet style!\nConfigure puppet to create a 4GB file /swapfile with the command dd if=/dev/zero of=/swapfile bs=2M count=2048. Look through the flags to the exec resource to see how you can do this.\nNow configure Puppet to run mkswap /swapfile \u0026amp;\u0026amp; swapon /swapfile unless swap is currently active, which you can check by seeing if swapon -s | grep /swapfile returns a zero code. There are two arguments that can do this, unless or onlyif. Experiment to see which one works.\nChecking Part h # Run swapon -s, and check that /swapfile is listed. Ensure that there is no extranous output when you run puppet, if your checks are correctly done, this shouldn\u0026rsquo;t happen. Check /home/minecraft/logs/latest.log to make sure that the server has start up properly. If it has, then congratulations!\nPart i: (Bonus, running Minecraft) # Due to security issues, the Minecraft server running is only listening to 127.0.0.1, which means by default you can only access a Minecraft client running on the VM. You have two ways to get around this. One is changing server-ip in server.properties to a blank string (i.e. server-ip=), which will allow access by anybody. If you do this you probably want to set up a whitelist. The other option is SSH port forwarding. The command, if run on your machine, captures traffic at port 25565 on your local computer, and forwards them to port 25565 on your VM. The command will run forever, just leave it in the background while you try to connect.\nssh -NL 25565:localhost:25565 \u0026lt;username\u0026gt;@\u0026lt;username\u0026gt;.decal.ocfhosted.com If you chose the first option, you can connect by typing your domain name (e.g. .decal.ocfhosted.com) or IP into minecraft, if you chose the second, you can connect to localhost.\nPart 3: Cleanup # There is currently a cronjob copying the minecraft world every minute. That might run you out of disk space. To disable that, you should run sudo crontab -e and remove the line for the backups.\nTrying to run a Minecraft Server constantly might also eat up some system resources. You can stop and disable the minecraft systmemd unit manually if it is causing issues.\nIf you added the swapfile, you might want to remove that.\nAnother way you can clean up is with puppet. By default, puppet doesn\u0026rsquo;t remove files it doesn\u0026rsquo;t know about. However, you can use ensure =\u0026gt; absent to make sure files are gone, and similarly for the other resource types.\nPart 4: Submission # Congratulations on finishing the lab!\nTo submit, copy paste the code you have for each section into the gradescope submission.\n"},{"id":22,"href":"/labs/11/","title":"Lab 11 - Kubernetes","section":"Labs","content":" Table of contents # {: .no_toc .text-delta }\nTOC {:toc} Overview # NOTE: This lab is completely optional. Completing it before the late lab deadline will count as an additional completed, on-time lab (so please try it out if you weren\u0026rsquo;t able to finish a previous lab)!\nThis lab is designed to give you some hands-on experience with Kubernetes. By the end of this lab, you should be able to:\nUnderstand the basic components of a Kubernetes deployment, including pods, services, and ingresses Run your own simple Kubernetes deployment Keep track of your answers to the questions, as you\u0026rsquo;ll need to submit them to Gradescope.\nBasic Concepts # For your own future reference, answer the following conceptual questions on Gradescope:\nQuestion 1a. In your own words, describe what Kubernetes is, and why it is useful (i.e. what problems it solves).\nQuestion 1b. What are some similarities and differences between Kubernetes and Docker?\nResources # In addition to the standard \u0026ldquo;just Google it\u0026rdquo; procedure, you can find answers to your many Kubernetes-related questions in the following resources:\nKubernetes documentation Kubernetes deployments njha\u0026rsquo;s kubernetes intro Actual OCF kubernetes deployment kubectl cheatsheet Getting started with kind # kind (Kubernetes in Docker) is a user-friendly way to run a single-node Kubernetes cluster locally on your computer. A popular alternative (and another valid way to complete this lab) is minikube which provides a variety of other ways to run a single-node Kubernetes cluster if you prefer to not use Docker. We chose to use kind in this guide because it supports IPv6 unlike minikube, and at the moment the VMs we provide are IPv6 only. Other popular Kubernetes distributions include k3s and microk8s, which are more feature-rich but more involved to set up compared to kind and minikube.\nTo begin, you can follow the official getting started guide for installation instructions (we recommend you install from release binaries).\nInstallation notes # Remember to run sudo usermod -aG docker $USER \u0026amp;\u0026amp; newgrp docker if you\u0026rsquo;re getting Docker permissions issues. If the kubectl command is not found, follow the instructions to install it. Confirm successful install # Question 2a. What command can you run to get all pods in all namespaces?\nQuestion 2b. What is the output of that command? (hint: \u0026ldquo;No resources found in default namespace.\u0026rdquo; is an incorrect answer- there should be something running if your install was successful)\nCreating your first deployment # For this first part, we\u0026rsquo;ll walk through how to set up a simple deployment of kubedoom using your new cluster.\nFirst, you\u0026rsquo;ll want to fetch the source code: git clone https://github.com/storax/kubedoom \u0026amp;\u0026amp; cd kubedoom.\nNext, run kubectl apply -k manifest/ to create all the resources.\nOnce this completes, you should have one new deployment (kubectl get deployments -A) and one new pod (kubectl get pods -A). It may take a couple minutes for the pod to show as \u0026ldquo;ready\u0026rdquo;.\nHowever, you still won\u0026rsquo;t be able to access this pod from the outside world! In order to do so, we\u0026rsquo;ll need to create a service and expose it:\nRun kubectl expose deployment kubedoom -n kubedoom --type=NodePort --port=5900. This will take the deployment we just made in the namespace kubedoom, and map it to a new service. If you now run kubectl get svc -A, you should see a new service of type NodePort listed. Port forward the service from your kind container by using kubectl port-forward service/kubedoom 5900 --address '127.0.0.1,::' -n kubedoom. This will allow you to access the service from either your VM at localhost:5900 or from outside with .decal.ocfhosted.com:5900. Try running telnet with telnet \u0026lt;username\u0026gt;.decal.ocfhosted.com 5900 on your local computer to make sure you can access it! If you\u0026rsquo;re able to connect and it doesn\u0026rsquo;t disconnect you immediately, then it should be working (you can press control-] and then type quit to exit). Use \u0026lt;username\u0026gt;.decal.ocfhosted.com:5900 as your VNC address in the next step. If you\u0026rsquo;re not able to connect, then you\u0026rsquo;ll probably have to port forward (run ssh \u0026lt;username\u0026gt;@\u0026lt;username\u0026gt;.decal.ocfhosted.com -J \u0026lt;username\u0026gt;@ssh.ocf.berkeley.edu -L 5900:localhost:5900 in another window) and then try telnet localhost 5900. If that works then use localhost:5900 as your VNC address in the next step. Finally, let\u0026rsquo;s access our kubedoom instance. The pod is actually running a GUI application, which can be accessed using VNC. You can download your VNC viewer of choice (some popular choices include TigerVNC, TightVNC, and RealVNC) and use the address from the telnet step to connect. The password for the VNC connection is idbehold. If all goes well, you should see a window that looks like this!\nQuestion 3a. Upload a screenshot of your working Kubedoom instance. If you were unable to get it to work, describe your debugging journey instead, and where you got stuck.\nHelm # Since many people have probably needed to deploy the same services that you\u0026rsquo;re hoping to deploy, chances are you\u0026rsquo;ll be able to find all the configurations you need online already! Helm is a package manager for Kubernetes, which makes it easy to find and manage these configs. Similarly to a package manager like apt for Linux, Helm will automatically download and install whatever you want it to with a few commands.\nYou can install Helm using this guide.\nOnce you\u0026rsquo;ve got it installed, let\u0026rsquo;s create a basic mocktail deployment by following the instructions below:\n$ helm repo add ocf https://decal.ocf.berkeley.edu/helm/ $ helm install mocktail ocf/mocktail Extending Helm deployments # Although taking the default deployment from Helm will be enough in some cases, we might also want to change up the configuration. Fortunately, Helm lets us do this!\nYour task: Figure out a way to modify Mocktail such that:\nIt runs on its own namespace mocktail-space, Its name is changed to ocf-mocktail, There are a minimum of 3 Mocktail pods running at any time. Hints:\nUse the default values.yaml file provided by the Mocktail chart maintainers for reference. Here\u0026rsquo;s some documentation on values files: Best practices dictate that you should not specify a custom namespace in the values file. Can you modify the commands you run to get around this? You can specify the --dry-run flag to debug without actually committing any changes. Question 4a. If applicable, paste the values.yaml file you created.\nQuestion 4b. Paste the command(s) you ran to create your Helm deployment.\nQuestion 4c. Paste the output of kubectl get deployments -A showing that your custom namespace appears.\nQuestion 4d. Paste the output of kubectl get pods -A showing that you have 3 ocf-mocktail pods running.\nChoose your own adventure # At this point, you should hopefully have an idea of how to create deployments and modify them to suit your needs!\nNow, we will provide the opportunity for you to find your own deployment(s) to create- you\u0026rsquo;re welcome to try whatever you find interesting.\nRequirements: You should host a service on your kind cluster that is externally accessible on your computer through some means (whether that be a GUI like kubedoom, web client like mocktail, or CLI). Document the process you took to install and expose this service.\nSome suggestions include but are not limited to:\nRun your own blog using Ghost Run your own wiki using Outline Run a Minecraft server Run kubeinvaders to stress-test your cluster Questions # Question 5a. What did you choose to install?\nQuestion 5b. Upload a screenshot of your working installation, or describe how/why you got stuck while trying to install it.\nQuestion 5c. Document any steps you took and commands you ran to create this deployment.\nQuestion 5d. What is one new thing you learned about Kubernetes, Linux, or system administration while creating this deployment?\n"},{"id":23,"href":"/labs/12/","title":"Lab 12 - CUDA","section":"Labs","content":"This lab is completely optional and is not worth any credit.\nAccess the lab here: https://colab.research.google.com/drive/19cOYch-OkLKqMTcrhpxMdiS0Fi4ATHMo?usp=sharing\n"},{"id":24,"href":"/resources/","title":"Resources","section":"Home","content":"Linux SysAdmin DeCal: Reading/Resource List\nSpring 2024\nLab\nTopic\nReading\n1\nHistory of UNIX, Intro to Shell, FOSS\nIntro to Linux man page http://man7.org/linux/man-pages/man1/intro.1.html\nFOSS licenses https://choosealicense.com/licenses/\nBasic terminal commands https://github.com/juanfrans/GSAPP-AP/wiki/Basic-Terminal-Commands\nResource: tldr is a nice tool for searching up commands https://tldr.inbrowser.app/\n2\nCore Shell \u0026amp; Shell Scripting\nCore Shell\nCommand line shortcuts http://teohm.com/blog/shortcuts-to-move-faster-in-bash-command-line/\nHow to learn vim https://medium.com/actualize-network/how-to-learn-vim-a-four-week-plan-cd8b376a9b85\nTmux cheat sheet https://gist.github.com/MohamedAlaa/2961058\nShell Scripting\nBash reference manual https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Introduction\nShell Tools and Scripting https://missing.csail.mit.edu/2020/shell-tools/\nBash Script Examples\nhttps://linuxhint.com/30_bash_script_examples/\n3\nPackages\nFPM Documentation https://github.com/jordansissel/fpm/wiki\ndpkg man page https://linux.die.net/man/1/dpkg\napt man page https://linux.die.net/man/8/apt\nDevelopers shouldn\u0026rsquo;t distribute their own software by Drew DeVault\nRolling distribution releases versus periodic releases are a tradeoff by Chris Siebenmann\nPackage Management by the DebianWiki\npacman by ArchWiki\nDebian Packaging Tutorial. You can put this in your /usr/share/doc/ by installing packaging-tutorial\nDebian Binary Package Building HOWTO by Chr. Clemens Lee\n4\nServices\nSystemd as a bootup manager http://0pointer.de/blog/projects/systemd-for-admins-1.html\nSystemd internet services http://0pointer.de/blog/projects/socket-activated-containers.html\nUnderstanding systemd units and unit services\nhttps://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files\n5\nNetworking 101\nCurl vs wget https://daniel.haxx.se/docs/curl-vs-wget.html\nTCP vs UDP https://www.guru99.com/tcp-vs-udp-understanding-the-difference.html\nOptional: Hexadecimal https://en.wikipedia.org/wiki/Hexadecimal\n6\nWeb Servers\nHAProxy https://www.haproxy.com/blog/the-four-essential-sections-of-an-haproxy-configuration\nDNS guide https://www.digitalocean.com/community/tutorials/an-introduction-to-dns-terminology-components-and-concepts\n7\nSecurity Fundamentals\nGnupg privacy handbook https://gnupg.org/gph/en/manual.pdf\nOpenPGP history https://www.openpgp.org/about/history/\n8\nVersion Control and Backups\nGit tutorial https://www.vogella.com/tutorials/Git/article.html\n9\nDocker\nDocker overview https://docs.docker.com/get-started/overview/\nDockerfile best practices https://docs.docker.com/develop/develop-images/dockerfile_best-practices/\n10\nKubernetes\nKubernetes deployments doc https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\nOCF’s kubernetes https://github.com/ocf/kubernetes\n1\nPuppet (Optional)\nPuppet documentation https://puppet.com/docs/puppet/latest/puppet_index.html\n"}]